[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pristine Seas Science Team SOP",
    "section": "",
    "text": "Living Document\n\n\n\nThis SOP is maintained collaboratively and updated regularly. Last updated: May 08, 2025."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Pristine Seas Science Team SOP",
    "section": "Introduction",
    "text": "Introduction\nWelcome to the Pristine Seas Science Team Standard Operating Procedures (SOP). This document serves as the comprehensive guide for conducting scientific research across Pristine Seas expeditions and projects. It establishes standardized protocols, workflows, and best practices to ensure consistency, reproducibility, and quality in all research activities.\n\nOur Mission\nPristine Seas works to explore, document, and protect vital places in the ocean. As the scientific foundation of this mission, our team conducts rigorous research to assess marine ecosystems and provide the evidence needed to support conservation efforts.\n\n\nCore Research Methods\nOur team uses a diverse set of integrated scientific methods to study marine ecosystems:\n\nBenthic surveys to quantify bottom types and invertebrates\nReef fish surveys to document fish communities\nEnvironmental DNA (eDNA) to assess overall biodiversity\nBaited Remote Underwater Video Systems (BRUVS) to quantify predatory species\nSeabird and marine mammal surveys\nDeep water surveys using ROVs, submersibles, and drop-cameras\n\nExplore our methods →\n\n\nPurpose of this SOP\nThis SOP provides:\n\nCollaborative practices to enhance team efficiency\nStandardized protocols for data collection across expeditions\nData management workflows for organizing and storing data\nAnalytical frameworks for consistent data processing and analysis\n\nThe SOP ensures that our scientific practices meet the highest standards of rigor, transparency, and reproducibility. By following these guidelines, we produce reliable data that can inform conservation decisions and contribute to our understanding of marine ecosystems."
  },
  {
    "objectID": "index.html#core-principles",
    "href": "index.html#core-principles",
    "title": "Pristine Seas Science Team SOP",
    "section": "Core Principles",
    "text": "Core Principles\nThe Pristine Seas Science Team is guided by these fundamental principles in all our work:\n\n\n\nScientific Excellence\n\nCuriosity\nRigor\nPeer review\nImpact driven\n\n\n\n\nOpen Science\n\nReproducibilty\nTransparency\nFAIR data principles\n\n\n\n\nCollaborative Research\n\nInterdisciplinary approaches\nLocal scientist engagement\nBroad partner network"
  },
  {
    "objectID": "index.html#our-collaborative-approach",
    "href": "index.html#our-collaborative-approach",
    "title": "Pristine Seas Science Team SOP",
    "section": "Our Collaborative Approach",
    "text": "Our Collaborative Approach\nThe Pristine Seas Science Team works across an integrated set of platforms:\n\n\n\n\n\n\n\n GitHub\n\n\n\nVersion control for code, analysis, and documentation\n\n\n\n\n\n\n\n\n Google Drive\n\n\n\nCollaborative document editing and data storage\n\n\n\n\n\n\n\n\n Zotero\n\n\n\nReference management and bibliography\n\n\n\n\n\n\n\n\n BigQuery\n\n\n\nCentralized database for expedition data\n\n\n\nLearn more about our infrastructure →"
  },
  {
    "objectID": "index.html#get-started",
    "href": "index.html#get-started",
    "title": "Pristine Seas Science Team SOP",
    "section": "Get Started",
    "text": "Get Started\nReady to dive in? Explore these key sections:\n\n\nExpedition Planning\nPrepare for successful field research with comprehensive planning guidelines\n\n\nField Methods\nStandardized protocols for all Pristine Seas research methods\n\n\nData Science\nData workflows, R package documentation, and analysis standards\n\n\n\nMedia Library\nProtocols for media collection, organization, and metadata requirements"
  },
  {
    "objectID": "collaborative-infra/index.html",
    "href": "collaborative-infra/index.html",
    "title": "Overview",
    "section": "",
    "text": "Our collaborative infrastructure is designed to support expedition-based workflows, streamlining data collection, processing, and analysis across diverse environments. Each tool serves a specific role in our research and data lifecycle, from real-time field data entry to long-term archival and analysis. This interconnected system enables seamless collaboration, robust data management, and scientific rigor at every stage\n\n\n\n Google Drive\nCentralized storage hub for all expedition data, documents, and media.\nDetails →\n\n\n\n GitHub\nRepository for each expedition and project’s code and analysis.\nDetails →\n\n\n\n\n\n\n BigQuery\nCentralized database for integrated data over 10+ years of expeditions.\nDetails →\n\n\n\n Argo NAS\nAt-sea hub for collaborative work and file sharing.\nDetails →\n\n\n\n\n\n\n Zotero\nReference management for general and expedition-specific literature.\nDetails →",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Overview"
    ]
  },
  {
    "objectID": "collaborative-infra/index.html#overview",
    "href": "collaborative-infra/index.html#overview",
    "title": "Overview",
    "section": "",
    "text": "Our collaborative infrastructure is designed to support expedition-based workflows. Each tool serves a specific purpose in the research and data lifecycle.\n\n\n\n\nCentralized storage hub for all expedition data, documents, and media.\nDetails →\n\n\n\n\nRepository for each expedition and project’s code and analysis.\nDetails →\n\n\n\n\n\n\n\nReference management for general and expedition-specific literature.\nDetails →\n\n\n\n\nCentralized database for integrated expedition data.\nDetails →",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Overview"
    ]
  },
  {
    "objectID": "collaborative-infra/google_drive.html",
    "href": "collaborative-infra/google_drive.html",
    "title": "Google Drive Organization",
    "section": "",
    "text": "Google Drive serves as our centralized storage hub for all expedition data, documents, and media."
  },
  {
    "objectID": "collaborative-infra/google_drive.html#overview",
    "href": "collaborative-infra/google_drive.html#overview",
    "title": "Google Drive Organization",
    "section": "",
    "text": "Google Drive serves as our centralized storage hub for all expedition data, documents, and media."
  },
  {
    "objectID": "collaborative-infra/google_drive.html#structure",
    "href": "collaborative-infra/google_drive.html#structure",
    "title": "Google Drive Organization",
    "section": "Structure",
    "text": "Structure\n\nExpeditions folder (primary organization unit)\n\nOne subfolder per expedition\nStandard folders for data, presentations, plans, etc.\n\nProjects folder for cross-expedition work\nManuscripts and publications\nPresentations\nEquipment inventory\nAdministrative documents"
  },
  {
    "objectID": "collaborative-infra/google_drive.html#best-practices",
    "href": "collaborative-infra/google_drive.html#best-practices",
    "title": "Google Drive Organization",
    "section": "Best Practices",
    "text": "Best Practices\n\nConsistent naming conventions\nProper access permissions\nRegular organization and cleanup"
  },
  {
    "objectID": "collaborative-infra/drive.html",
    "href": "collaborative-infra/drive.html",
    "title": "Google Drive",
    "section": "",
    "text": "Google Drive serves as the primary collaborative hub for the Pristine Seas Science Team. As the foundation of our digital infrastructure, Drive provides centralized storage, enables collaboration, and ensures continuity of our scientific work.\n\nCentral Repository: Primary and secondary data from field to analysis\nDocument Management: Expedition plans, permits, reports, and manuscripts\nCollaboration Platform: Real-time collaborative editing and review\nAsset Library: Visual materials, presentations, and resources",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#overview",
    "href": "collaborative-infra/drive.html#overview",
    "title": "Google Drive",
    "section": "",
    "text": "Google Drive serves as the primary collaborative hub for the Pristine Seas Science Team. As the foundation of our digital infrastructure, Drive provides centralized storage, enables collaboration, and ensures continuity of our scientific work.\n\nCentral Repository: Primary and secondary data from field to analysis\nDocument Management: Expedition plans, permits, reports, and manuscripts\nCollaboration Platform: Real-time collaborative editing and review\nAsset Library: Visual materials, presentations, and resources",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#structure",
    "href": "collaborative-infra/drive.html#structure",
    "title": "Google Drive",
    "section": "Structure",
    "text": "Structure\nThe Pristine Seas Drive has six main folders, each with a specific purpose:\nOur folder structure is designed around our core workflow, separating expedition-specific content from broader projects and reference materials. This organization helps maintain data integrity while enabling efficient cross-project analysis and knowledge sharing.\n📁 expeditions/\n   └── 📁 COL_2022/\n   └── 📁 PLW_2023/\n   └── 📁 MDV_2024/\n\n📁 projects/\n   └── 📁 prj-PLW-sixgill/\n   └── 📁 prj-EU-trawl/\n   └── 📁 prj-global-seamounts/\n\n📁 datasets/\n   └── 📁 global/\n   └── 📁 regional/\n\n📁 presentations/\n   └── 📁 expedition_reports/\n   └── 📁 conference_presentations/\n   └── 📁 visual_assets/\n\n📁 education/\n\n📁 legacy_data/",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#best-practices",
    "href": "collaborative-infra/drive.html#best-practices",
    "title": "Google Drive",
    "section": "Best Practices",
    "text": "Best Practices\n\nKeep root folders clean - place files in appropriate subfolders\nUse consistent file types - prefer open formats where possible\nAdd context with README files - in each major folder\nClean up temporary files - don’t accumulate drafts\nLink to related resources - connect with GitHub repos and Zotero",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html",
    "href": "collaborative-infra/github.html",
    "title": "GitHub",
    "section": "",
    "text": "GitHub serves as the foundation of our code management system, providing robust version control, collaborative workflows, and reproducible research capabilities. This central platform enables the Pristine Seas Science Team to maintain high standards of scientific rigor and transparency while facilitating efficient collaboration across our distributed team.\n\n\n\nVersion control: Track changes over time with complete history\nCollaboration: Multiple scientists can contribute to the same codebase\nReproducibility: Code tied to specific analyses or expeditions is preserved exactly as used\nKnowledge sharing: Public repositories make methods transparent to the broader scientific community\nQuality control: Pull request review system ensures code quality and consistency",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#overview",
    "href": "collaborative-infra/github.html#overview",
    "title": "GitHub",
    "section": "",
    "text": "GitHub serves as the foundation of our code management system, providing robust version control, collaborative workflows, and reproducible research capabilities. This central platform enables the Pristine Seas Science Team to maintain high standards of scientific rigor and transparency while facilitating efficient collaboration across our distributed team.\n\n\n\nVersion control: Track changes over time with complete history\nCollaboration: Multiple scientists can contribute to the same codebase\nReproducibility: Code tied to specific analyses or expeditions is preserved exactly as used\nKnowledge sharing: Public repositories make methods transparent to the broader scientific community\nQuality control: Pull request review system ensures code quality and consistency",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#repository-structure",
    "href": "collaborative-infra/github.html#repository-structure",
    "title": "GitHub",
    "section": "Repository Structure",
    "text": "Repository Structure\nExpedition repositories follow a standardized structure to ensure consistency and ease of navigation. This structure helps new team members quickly understand our workflow and facilitates efficient collaboration.\nexp-[ISO3]-[YEAR]/\n├── .github/              # GitHub specific files (actions, templates)\n├── R/                    # R functions and utility scripts\n├── pipeline/             # Data processing pipelines\n│   ├── pipe_benthic.qmd    # Benthic data processing\n│   ├── pipe_fish.qmd       # Fish data processing\n│   ├── pipe_pbruv.qmd      # BRUVS data processing\n├── eda/                  # Exploratory data analysis\n│   ├── eda_lpi.qmd       # Benthic data analysis\n│   ├── eda_fish.qmd      # Fish data analysis\n│   └── eda_pbruv.qmd     # Pelagic BRUVS data analysis\n├── docs/                 # qmds are rendered here\n├── .gitignore            # Files to exclude from version control\n├── README.md             # Repository overview and instructions\n└── exp-[ISO3]-[YEAR].Rproj  # RStudio project file\nProject and infrastructure repositories have flexible structures based on their specific needs, but should still maintain clear organization and documentation.\n\n\n\n\n\n\nData Storage Guidelines\n\n\n\nWe do not store data in GitHub repositories. This is both a practical consideration (GitHub has file size limits) and a scientific best practice (data should be managed separately from code).\nInstead:\n\nRaw data is stored in Google Drive (see Google Drive documentation)\nProcessed data is stored in BigQuery (see BigQuery documentation)",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#basic-workflow",
    "href": "collaborative-infra/github.html#basic-workflow",
    "title": "GitHub",
    "section": "Basic Workflow",
    "text": "Basic Workflow\n\nClone the expedition repository\nCreate branches for specific analyses\nCommit code with clear messages\nCreate pull requests for review\nMerge approved changes",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html",
    "href": "collaborative-infra/zotero.html",
    "title": "Zotero",
    "section": "",
    "text": "The Pristine Seas Science Team maintains a centralized Zotero library for managing scientific literature. This shared resource ensures all team members have access to relevant publications, enabling consistent citation practices and facilitating collaborative research and writing. The library integrates with our broader collaborative infrastructure, maintaining parallel organizational structures with Google Drive and GitHub repositories.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#overview",
    "href": "collaborative-infra/zotero.html#overview",
    "title": "Zotero",
    "section": "",
    "text": "The Pristine Seas Science Team maintains a centralized Zotero library for managing scientific literature. This shared resource ensures all team members have access to relevant publications, enabling consistent citation practices and facilitating collaborative research and writing. The library integrates with our broader collaborative infrastructure, maintaining parallel organizational structures with Google Drive and GitHub repositories.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#organization",
    "href": "collaborative-infra/zotero.html#organization",
    "title": "Zotero Library",
    "section": "Organization",
    "text": "Organization\n\nMain library with shared access\nCollections organized by:\n\nExpeditions\nResearch methods\nEcosystems\nGeographic regions",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero Library"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#workflow",
    "href": "collaborative-infra/zotero.html#workflow",
    "title": "Zotero Library",
    "section": "Workflow",
    "text": "Workflow\n\nAdd references with browser extension\nOrganize into appropriate collections\nAdd PDFs when available\nUse consistent tagging system\nExport citations for manuscripts",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero Library"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html",
    "href": "collaborative-infra/bigquery.html",
    "title": "BigQuery",
    "section": "",
    "text": "The Pristine Seas Science Database is a centralized, modular system hosted in Google BigQuery that serves as the foundation of our data management infrastructure. This system integrates ecological data collected across more than a decade of scientific expeditions, supporting high-integrity, reproducible research on marine biodiversity and informing global ocean conservation policy.\n\n\nGoogle BigQuery offers several advantages for marine ecological data:\n\nScalability: Handles our growing dataset spanning 40+ expeditions without performance degradation\nIntegration: Seamlessly connects with our R-based analysis workflows\nCollaboration: Enables standardized access across our distributed research team\nFuture-proofing: Provides a robust platform that can evolve with our research needs\n\nNote: BigQuery is were Global Fishing Watch data lives and we have access to the raw backend data.\n\n\n\nOur database implementation adheres to the FAIR data principles:\n\n\n\n\n\nUnique and unified IDs\nWoRMS-linked taxonomy\nConsistent spatial hierarchy\n\n\n\n\n\nQuery-ready BigQuery tables\nControlled access and permissions\nVaried connection options\n\n\n\n\n\nSpatial reference system\nHarmonized taxonomic backbone\nConsistent units (cm, g, m²)\n\n\n\n\n\nComprehensive metadata\nReproducible code\nClear provenance6",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#overview",
    "href": "collaborative-infra/bigquery.html#overview",
    "title": "BigQuery",
    "section": "",
    "text": "The Pristine Seas Science Database is a centralized, modular system hosted in Google BigQuery that serves as the foundation of our data management infrastructure. This system integrates ecological data collected across more than a decade of scientific expeditions, supporting high-integrity, reproducible research on marine biodiversity and informing global ocean conservation policy.\n\n\nGoogle BigQuery offers several advantages for marine ecological data:\n\nScalability: Handles our growing dataset spanning 40+ expeditions without performance degradation\nIntegration: Seamlessly connects with our R-based analysis workflows\nCollaboration: Enables standardized access across our distributed research team\nFuture-proofing: Provides a robust platform that can evolve with our research needs\n\nNote: BigQuery is were Global Fishing Watch data lives and we have access to the raw backend data.\n\n\n\nOur database implementation adheres to the FAIR data principles:\n\n\n\n\n\nUnique and unified IDs\nWoRMS-linked taxonomy\nConsistent spatial hierarchy\n\n\n\n\n\nQuery-ready BigQuery tables\nControlled access and permissions\nVaried connection options\n\n\n\n\n\nSpatial reference system\nHarmonized taxonomic backbone\nConsistent units (cm, g, m²)\n\n\n\n\n\nComprehensive metadata\nReproducible code\nClear provenance6",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#data-structure",
    "href": "collaborative-infra/bigquery.html#data-structure",
    "title": "BigQuery",
    "section": "Data Structure",
    "text": "Data Structure\n\nOrganized by research method and expedition\nStandardized schema across expeditions\nConsistent field naming conventions",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#workflow",
    "href": "collaborative-infra/bigquery.html#workflow",
    "title": "BigQuery",
    "section": "Workflow",
    "text": "Workflow\n\nData collection in the field\nInitial processing and validation\nImport to BigQuery tables\nIntegration with R for analysis\nExport for reporting and visualization",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "field-methods/index.html",
    "href": "field-methods/index.html",
    "title": "Overview",
    "section": "",
    "text": "The Pristine Seas Science Team employs a range of complementary research methods to document and study marine ecosystems. Each method provides unique insights into different components of ocean biodiversity, ecological processes, and ecosystem health.\nThis integrated research approach allows us to:\nThese insights are fundamental for effective conservation and our job includes to translate them into actionable strategies for marine protection.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/index.html#core-research-methods",
    "href": "field-methods/index.html#core-research-methods",
    "title": "Field Methods",
    "section": "Core Research Methods",
    "text": "Core Research Methods\n\n\n\n\nBenthic Surveys\n\nDepths: 0-30m | Target: Benthos\n\n\nPoint-intercept transects\n\n\nInvertebrate counts\n\n\nCoral recruits counts\n\n\nProtocol →\n\n\n\nFish Surveys\n\nDepths: 0-30m | Target: Reef Fish\n\n\nBelt transects\n\n\nSize estimation\n\n\nSpecies identification\n\n\nProtocol →\n\n\n\n\n\nEnvironmental DNA\n\nDepths: All zones | Target: All taxa\n\n\nWater filtration\n\n\nMetabarcoding\n\n\nSequence analysis\n\n\nProtocol →\n\n\n\nSeabed BRUVS\n\nDepths: 10-100m | Target: Reef Predators\n\n\nBaited remote video systems\n\n\nMaxN measurements\n\n\nLength estimation\n\n\nProtocol →\n\n\n\n\n\nPelagic BRUVS\n\nDepths: Surface | Target: Pelagic Predators\n\n\nOffshore, mid-water deployments\n\n\nSpecies composition\n\n\nRelative abundance\n\n\nProtocol →\n\n\n\nSeabird Surveys\n\nZone: Surface | Target: Birds\n\n\nLine transects\n\n\nPoint counts\n\n\nSpecies identification\n\n\nProtocol →\n\n\n\n\n\nMarine Mammal Surveys\n\nZone: Surface | Target: Mammals\n\n\nVisual transects\n\n\nBehavioral sampling\n\n\nPhoto identification\n\n\nProtocol →\n\n\n\nROV Surveys\n\nDepths: to 1000m | Target: Deep biota\n\n\nTransect video recording\n\n\nSpecies identification\n\n\nHabitat documentation\n\n\nProtocol →\n\n\n\n\n\nSubmersible Surveys\n\nDepths: to 1300m | Target: Deep biota\n\n\nManned submersible\n\n\nVideo documentation\n\n\nIn-situ observations\n\n\nProtocol →\n\n\n\nDeep Sea Drop-Cameras\n\nDepths: to 6000m | Target: Deep sea biota\n\n\nSelf-contained systems\n\n\nHigh-definition video\n\n\nExtreme depth capability\n\n\nProtocol →",
    "crumbs": [
      "Home",
      "Field Methods",
      "Field Methods"
    ]
  },
  {
    "objectID": "field-methods/index.html#method-integration",
    "href": "field-methods/index.html#method-integration",
    "title": "Field Methods",
    "section": "Method Integration",
    "text": "Method Integration\nWhile each method is described separately in this SOP, our research design integrates these approaches to create a comprehensive ecological assessment. Sampling sites are strategically selected to enable cross-method data integration.\n\n\n\n\n\n\nData Integration\n\n\n\nAll methods follow standardized spatial coordinates, site naming conventions, and habitat classifications to facilitate integrated analysis across datasets.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Field Methods"
    ]
  },
  {
    "objectID": "field-methods/index.html#data-processing-and-analysis",
    "href": "field-methods/index.html#data-processing-and-analysis",
    "title": "Field Methods",
    "section": "Data Processing and Analysis",
    "text": "Data Processing and Analysis\nEach field method has specific data processing workflows and analytical approaches outlined in its respective protocol. However, all methods adhere to common standards for:\n\nData entry and validation\nQuality control procedures\nFile naming and organization\nStatistical approach and R code templates\nIntegration with the centralized database\n\nThese standardized protocols ensure data comparability across expeditions and research sites, enabling robust global analyses of marine ecosystems.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Field Methods"
    ]
  },
  {
    "objectID": "field-methods/index.html#integration",
    "href": "field-methods/index.html#integration",
    "title": "Overview",
    "section": "Integration",
    "text": "Integration\nOur field research strategically integrates multiple assessment methods to provide comprehensive ecosystem insights beyond what individual techniques can reveal. Sampling sites are carefully selected to maximize spatial and temporal alignment across methods, enabling analyses of relationships between different ecosystem components.\nTo ensure seamless data integration, all methods follow standardized protocols including uniform taxonomic references, consistent metadata structures, shared spatial hierarchies, and compatible statistical approaches. This standardization facilitates robust cross-method analyses that reveal critical ecological relationships and functions.\n\n\n\n\n\n\nHierarchical spatial structure\n\n\n\nOur nested structure organizes all collected data into meaningful spatial contexts:\n\nExpedition: A complete research campaign to a country or target area\nConvention: [ISO3]_[YEAR]\nExamples: PLW_2023, MDV_2024\n\nRegion: Broad geographic or administrative area\nExamples: Temotu Province, Manus Province\n\nSubregion: Intermediate unit like an island, atoll, gulf, or reef complex\nExamples: Duff Islands, Harengan\n\nLocality: Local named feature such as a islet, community, village\nExamples: Taumako, Pinyang island\n\nSite: Specific location where sampling methods are deployed\nConvention: [ISO3]_[YEAR]_[METHOD]_[SITE]\nExamples: PLW_2023_uvs_001, FJI_2023_pbruv_001\n\nStation: A discrete sampling unit within a site, usually depth strata\nConvention: [ISO3]_[YEAR]_[METHOD]_[SITE]_[STATION]\nExamples: PLW_2023_uvs_001_10m, PLW_2023_uvs_001_20m\n\nMeasurement/Observation: Individual data points collected at a station\nExamples: Fish count, Coral cover percentage, remote video footage\n\n\n\n\n\n\n\nThis allows for analyses at multiple scales while maintaining clear relationships between sampling elements.\n\n\n\nSampling Hierarchy\nThe table below outlines the spatial sampling structure for each method in the Pristine Seas Science Database. It defines the hierarchical relationship from sites to observations, ensuring clarity and consistency across protocols.\n\n\n\n\n\n\n\n\nPristine Seas Sampling Hierarchy\n\n\nSite &gt; Station &gt; Transect &gt; Observation\n\n\nMethod\nSite\nStation\nTransect\nObservation\n\n\n\n\nUVS\nDive survey\nDepth strata\nBLT (3), LPI (1), Inverts (1), Recruits (10)\nCounts, biomass, cover\n\n\neDNA\nWater collection site\nDepth strata\nWater bags or pumps\nSpecies DNA\n\n\nPelagic BRUVS\n5-rig BRUVS deployment\nRig\nN/A\nSpecies ID, length, MaxN\n\n\nSeabed BRUVS\nSingle BRUVS deployment\nSingle station\nN/A\nSpecies ID, length, MaxN\n\n\nSubmersible Surveys\nSub dive\nDepth strata\nVideo transects\nSpecies ID, counts, habitat\n\n\nDeep-Sea Cameras\nSingle camera deployment\nSingle station\nN/A\nSpecies ID, abundance\n\n\nROV Surveys\nROV dive\nDepth strata\nVideo transects\nSpecies ID, counts, habitat\n\n\nYSI Loggers\nLogger deployment\nSingle profile\nN/A\nTemp, salinity, DO, pH\n\n\nBird Surveys\nSurvey point\nSingle survey\nWalking transect or point count\nSpecies counts, behavior\n\n\n\n\n\n\n\nThe Pristine Seas Science Database serves as the central repository for this integrated data architecture, preserving methodological connections while maintaining data integrity. Complete documentation of database structure and integration protocols is available here.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/index.html#core-methods",
    "href": "field-methods/index.html#core-methods",
    "title": "Overview",
    "section": "Core Methods",
    "text": "Core Methods\n\n\n\n\nBenthic Surveys\n\nDepths: 0-30m | Target: Benthos\n\n\nPoint-intercept transects\n\n\nInvertebrate counts\n\n\nCoral recruits counts\n\n\nProtocol →\n\n\n\nFish Surveys\n\nDepths: 0-30m | Target: Reef Fish\n\n\nBelt transects\n\n\nSpecies identification\n\n\nSize and biomass estimation\n\n\nProtocol →\n\n\n\n\n\nEnvironmental DNA\n\nDepths: All zones | Target: All taxa\n\n\nWater filtration\n\n\nSequence analysis\n\n\nProtocol →\n\n\n\nSeabed BRUVS\n\nDepths: 10-100m | Target: Reef Predators\n\n\nStereo baited remote video systems\n\n\nRelative abundance (MaxN)\n\n\nLength estimation\n\n\nProtocol →\n\n\n\n\n\nPelagic BRUVS\n\nDepths: Surface | Target: Pelagic Predators\n\n\nStereo, Offshore, mid-water deployments\n\n\nSpecies composition\n\n\nMaxN and length estimates\n\n\nProtocol →\n\n\n\nSeabird Surveys\n\nZone: Surface | Target: Birds\n\n\nCoastal transects\n\n\nAt-sea point counts\n\n\nNesting areas, density estimates, diversity\n\n\nProtocol →\n\n\n\n\n\nMarine Mammal Surveys\n\nZone: Surface | Target: Mammals\n\n\nVisual timed transects\n\n\nAereal surveys\n\n\nPhoto identification\n\n\nProtocol →\n\n\n\nROV Surveys\n\nDepths: to 1000m | Target: Deep biota\n\n\nExploratory dives\n\n\nHorizontal video transects\n\n\nSpecies and habitat documentation\n\n\nProtocol →\n\n\n\n\n\nSubmersible Surveys\n\nDepths: to 1300m | Target: Deep biota\n\n\nExploratory dives\n\n\nHorizontal video transects\n\n\nIn-situ observations and specimen collection\n\n\nProtocol →\n\n\n\nDeep Sea Cameras\n\nDepths: to 6000m | Target: Deep sea biota\n\n\nDeep sea scavengers\n\n\nCommunity composition and relative abyundnce (MaxN)\n\n\nNew records and range extensions\n\n\nProtocol →",
    "crumbs": [
      "Home",
      "Field Methods",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/index.html#data-processing",
    "href": "field-methods/index.html#data-processing",
    "title": "Overview",
    "section": "Data Processing",
    "text": "Data Processing\nEach field method follows specific processing workflows, but all adhere to a standardized framework that ensures data quality, reproducibility, and integration. Our data processing approach balances method-specific requirements with system-wide standards.\n\nCommon Data Standards\nAll methods implement these critical standards:\n\nData Entry & Validation\n\nStructured data entry forms with built-in validation rules\nAutomated checks for impossible values and outlier detection\n\nQuality Control Procedures\n\nMulti-stage verification process (field, office, database)\nCross-method consistency checks for shared parameters\n\nFile Naming & Organization\n\nConsistent folder structure and file naming conventions\nVersion control system\n\nStatistical Approaches\n\nStandardized methods for handling zero-inflated ecological data\nConsistent treatment of temporal and spatial autocorrelation\n\nDatabase Integration\n\nAutomated (i wish) data ingestion pipelines for each method\nRelational table structures preserving cross-method linkages\nMetadata documentation\n\n\n\n\nMethod-Specific Workflows\nEach method’s processing workflow is fully documented and implemented in two Quarto scripts:\n\npipeline_[method].qmd: Data transformation pipeline from raw collection, QAQC, and output of analysis-ready tables for ingestion into the DB\neda_[method].qmd: Exploratory data analysis, visualization and statistics\n\nThese reproducible scripts ensure consistent processing across expeditions and enable efficient onboarding of new team members to our data workflows.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html",
    "href": "field-methods/uvs_overview.html",
    "title": "Overview",
    "section": "",
    "text": "Underwater visual surveys (UVS) are the cornerstone of Pristine Seas ecological assessments, providing a comprehensive, quantitative foundation for understanding marine ecosystem structure and function. These standardized methods enable robust comparisons across sites, regions, and time periods, creating a powerful global dataset to inform science-based conservation.\n\n\n\n\n\n\n\n\n\n\nFigure 1: Pristine Seas divers conducting underwater visual surveys. Left: Fish belt transect survey. Right: Benthic survey using line point intercept method.\n\nThrough a multi-method approach, we capture the key components of marine ecosystem health: fish populations, benthic composition, invertebrate communities, and coral recruitment. This holistic assessment provides a scientific basis for identifying conservation priorities and designing effective marine protected areas.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#introduction",
    "href": "field-methods/uvs_overview.html#introduction",
    "title": "Overview",
    "section": "",
    "text": "Underwater visual surveys (UVS) are the cornerstone of Pristine Seas ecological assessments, providing a comprehensive, quantitative foundation for understanding marine ecosystem structure and function. These standardized methods enable robust comparisons across sites, regions, and time periods, creating a powerful global dataset to inform science-based conservation.\n\n\n\n\n\n\n\n\n\n\nFigure 1: Pristine Seas divers conducting underwater visual surveys. Left: Fish belt transect survey. Right: Benthic survey using line point intercept method.\n\nThrough a multi-method approach, we capture the key components of marine ecosystem health: fish populations, benthic composition, invertebrate communities, and coral recruitment. This holistic assessment provides a scientific basis for identifying conservation priorities and designing effective marine protected areas.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#general-equipment-and-preparation",
    "href": "field-methods/uvs_overview.html#general-equipment-and-preparation",
    "title": "Underwater Visual Surveys",
    "section": "General Equipment and Preparation",
    "text": "General Equipment and Preparation\n\nEssential Equipment\n\n\n\n\n\n\n\n\nEquipment\nPurpose\nSpecifications\n\n\n\n\nTransect tapes (50m)\nEstablish survey area\nFiberglass, with meter markings\n\n\nDive slate with datasheets\nData recording\nWaterproof paper or plastic\n\n\nUnderwater camera\nDocumentation\nWith depth rating to at least 30m\n\n\nMeasuring tools\nSize estimation\nFish measuring board, calipers, rulers\n\n\nQuadrats\nArea delimitation\n25×25cm and 1×1m depending on method\n\n\nDepth gauge\nDepth verification\nDigital preferred\n\n\nGPS\nSite marking\nWaterproof or in dry bag on surface\n\n\nCompass\nNavigation\nWrist-mounted for convenience\n\n\n\n\n\nSite Selection\nSites are selected to represent the range of habitats within the study area. For each habitat type:\n\nSelect replicate sites (minimum of 3 per habitat type)\nRecord GPS coordinates for each site\nDocument site characteristics (depth, exposure, habitat type)\nTake photographs of the general site conditions\n\n\n\nTransect Deployment\nFor all underwater visual surveys:\n\nDeploy a minimum of 3 transects per site\nStandard transect length is 25m\nMaintain a consistent depth contour (±1m) along each transect\nAllow a minimum of 5m between adjacent transects\nRandomize starting points where possible\nRecord depth at the beginning, middle, and end of each transect\n\n\n\nObserver Training and Calibration\nAll observers must:\n\nComplete standardized training for each survey component\nDemonstrate proficiency in species identification\nPass size estimation tests with &gt;90% accuracy\nParticipate in regular calibration exercises\nCross-check identifications with photo documentation"
  },
  {
    "objectID": "field-methods/uvs_overview.html#fish-belt-transects",
    "href": "field-methods/uvs_overview.html#fish-belt-transects",
    "title": "Underwater Visual Surveys",
    "section": "Fish Belt Transects",
    "text": "Fish Belt Transects\nFish belt transects quantify the abundance, size, and diversity of fish populations.\n\n\n\nFish belt transect illustration\n\n\n\nProtocol Overview\n\nTwo divers work as a team along each transect\nFirst diver deploys the transect tape\nSecond diver follows after a 5-minute delay to allow fish to resume normal behavior\nObserver records all fishes within 2.5m on either side of the transect (5m total width)\nDifferent width bands may be used for different fish groups (e.g., 5m for large/mobile species, 2m for small/cryptic species)\n\n\n\nData Collection\nFor each fish observed:\n\nRecord species identification\nEstimate total length (TL) to the nearest cm\nCount individuals by species and size class\nNote behavior and interactions where relevant\n\n\n\nSize Estimation\nAccurate size estimation is critical:\n\nUse a calibrated measuring device for training\nPractice with objects of known size underwater\nConduct regular testing against known objects\nUse reference points on equipment for scale\nVerify estimations with photographic evidence when possible\n\n\n\nData Processing and Analysis\nFish belt transect data are processed to calculate:\n\nSpecies richness and diversity indices\nDensity (individuals per m²)\nBiomass using length-weight relationships\nSize structure of populations\nTrophic composition\n\n\n\nCode\n# Example code for processing fish belt transect data\nfish_data &lt;- read_csv(here(\"data\", \"raw\", \"fish_belt_transects.csv\"))\n\n# Calculate density\nfish_density &lt;- fish_data %&gt;%\n  group_by(site_id, habitat, species) %&gt;%\n  summarize(\n    count = sum(count),\n    area_surveyed = mean(transect_length) * mean(transect_width),\n    density = count / area_surveyed\n  )\n\n# Calculate biomass using length-weight relationship\nfish_biomass &lt;- fish_data %&gt;%\n  mutate(\n    weight_g = a_param * (length_cm^b_param),\n    biomass = weight_g * count / (transect_length * transect_width)\n  ) %&gt;%\n  group_by(site_id, habitat, species, trophic_group) %&gt;%\n  summarize(\n    total_biomass_g_m2 = sum(biomass)\n  )"
  },
  {
    "objectID": "field-methods/uvs_overview.html#line-point-intercept-lpi",
    "href": "field-methods/uvs_overview.html#line-point-intercept-lpi",
    "title": "Underwater Visual Surveys",
    "section": "Line Point Intercept (LPI)",
    "text": "Line Point Intercept (LPI)\nThe Line Point Intercept method assesses benthic community composition and substrate cover.\n\nProtocol Overview\n\nPoints are assessed at 25cm intervals along each 25m transect (100 points total)\nAt each point, the diver records what is directly beneath the transect tape\nBoth primary and secondary (understory) organisms are recorded where applicable\nPhotograph quadrats at regular intervals for validation\n\n\n\nBenthic Categories\nStandard benthic categories include:\n\n\n\n\n\n\n\n\nCode\nCategory\nDescription\n\n\n\n\nHC\nHard Coral\nScleractinian corals\n\n\nSC\nSoft Coral\nAlcyonaceans and other non-scleractinian anthozoans\n\n\nMA\nMacroalgae\nFleshy and calcareous macroalgae\n\n\nTA\nTurf Algae\nFilamentous algal assemblages &lt;2cm height\n\n\nCCA\nCrustose Coralline Algae\nPink to purple encrusting calcareous algae\n\n\nOI\nOther Invertebrates\nSponges, tunicates, anemones, etc.\n\n\nSD\nSand\nUnconsolidated sediment\n\n\nRB\nRubble\nCoral fragments and small rocks\n\n\nRK\nRock\nConsolidated reef framework or bedrock\n\n\n\n\n\nData Processing and Analysis\nLPI data are processed to calculate:\n\nPercent cover by category\nBenthic community composition\nSubstrate diversity indices\nRatio of biotic to abiotic cover\nCoral:algal ratios\n\n\n\nCode\n# Example code for processing LPI data\nlpi_data &lt;- read_csv(here(\"data\", \"raw\", \"lpi.csv\"))\n\n# Calculate percent cover\nbenthic_cover &lt;- lpi_data %&gt;%\n  group_by(site_id, habitat, category) %&gt;%\n  summarize(\n    points = n(),\n    total_points = n_distinct(point_id),\n    percent_cover = (points / total_points) * 100\n  ) %&gt;%\n  arrange(site_id, habitat, desc(percent_cover))"
  },
  {
    "objectID": "field-methods/uvs_overview.html#invertebrate-counts",
    "href": "field-methods/uvs_overview.html#invertebrate-counts",
    "title": "Underwater Visual Surveys",
    "section": "Invertebrate Counts",
    "text": "Invertebrate Counts\nInvertebrate surveys document the abundance and diversity of mobile invertebrates.\n\nProtocol Overview\n\nCount all target invertebrates within 1m on either side of the transect (2m total width)\nPlace 1×1m quadrats at 5m intervals along the transect for detailed assessment\nSearch carefully within complex reef structure\nUse flashlight to check crevices and undersides of structures\n\n\n\nTarget Taxa\nPriority invertebrate taxa include:\n\nEchinoderms (sea stars, urchins, sea cucumbers)\nMolluscs (particularly commercial species)\nCrustaceans (lobsters, large crabs)\nOther conspicuous mobile invertebrates\n\n\n\nData Processing and Analysis\nInvertebrate data are processed to calculate:\n\nDensity by taxon (individuals per m²)\nSize-frequency distributions for key species\nRelationship to benthic habitat characteristics\nIndicators of ecosystem health (e.g., urchin barrens)\n\n\n\nCode\n# Example code for processing invertebrate data\ninvert_data &lt;- read_csv(here(\"data\", \"raw\", \"invertebrates.csv\"))\n\n# Calculate density\ninvert_density &lt;- invert_data %&gt;%\n  group_by(site_id, habitat, taxon) %&gt;%\n  summarize(\n    count = sum(count),\n    area_surveyed = mean(transect_length) * mean(transect_width),\n    density = count / area_surveyed\n  ) %&gt;%\n  arrange(site_id, habitat, desc(density))"
  },
  {
    "objectID": "field-methods/uvs_overview.html#coral-recruit-surveys",
    "href": "field-methods/uvs_overview.html#coral-recruit-surveys",
    "title": "Underwater Visual Surveys",
    "section": "Coral Recruit Surveys",
    "text": "Coral Recruit Surveys\nCoral recruit surveys assess the reproductive success and recovery potential of coral communities.\n\nProtocol Overview\n\nPlace 25×25cm quadrats at 5m intervals along each transect\nPhotograph each quadrat for reference\nSearch carefully for coral recruits (colonies &lt;2cm diameter)\nIdentify recruits to the lowest taxonomic level possible\nMeasure maximum diameter of each recruit\n\n\n\nData Collection\nFor each quadrat:\n\nRecord quadrat ID and location along transect\nCount total number of recruits\nDocument genus/morphology when possible\nNote substrate type where recruits are found\nRecord evidence of recent mortality\n\n\n\nData Processing and Analysis\nCoral recruit data are processed to calculate:\n\nRecruit density (individuals per m²)\nTaxonomic composition of recruits\nSize distribution of recruits\nRelationship to adult coral cover\nSubstrate preference for settlement\n\n\n\nCode\n# Example code for processing coral recruit data\nrecruit_data &lt;- read_csv(here(\"data\", \"raw\", \"coral_recruits.csv\"))\n\n# Calculate recruit density\nrecruit_density &lt;- recruit_data %&gt;%\n  group_by(site_id, habitat, taxon) %&gt;%\n  summarize(\n    count = sum(count),\n    area_surveyed = n() * 0.0625,  # Number of 25×25cm quadrats (0.0625 m²)\n    density = count / area_surveyed\n  ) %&gt;%\n  arrange(site_id, habitat, desc(density))"
  },
  {
    "objectID": "field-methods/uvs_overview.html#quality-control-procedures",
    "href": "field-methods/uvs_overview.html#quality-control-procedures",
    "title": "Underwater Visual Surveys",
    "section": "Quality Control Procedures",
    "text": "Quality Control Procedures\nMaintaining data quality requires strict adherence to these procedures:\n\nEnter data from fieldbooks the same day of survey\nCross-check species identifications with photographs\nSave the field sheet for future QAQC if needed\nRegular reference to the UVS Sites Fieldbook to verify site metadata",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#data-integration",
    "href": "field-methods/uvs_overview.html#data-integration",
    "title": "Underwater Visual Surveys",
    "section": "Data Integration",
    "text": "Data Integration\nThe Pristine Seas methodology integrates data from all survey components to assess ecosystem health through a standardized set of ecological indicators:\nKey metrics calculated:\n\nBenthic composition (% hard coral and CCA cover)\nDegradation indicators (% cyanobacteria cover)\nFish community structure (total fish biomass)\nTrophic integrity (% biomass of sharks and top predators)\nInvertebrate status (density of key commercial species)\nReef recovery potential (coral recruitment density)\n\nThese metrics provide a holistic assessment of marine ecosystem condition, enabling effective conservation planning and monitoring. The co-located design of our surveys ensures valid ecological comparisons across components while maintaining methodological integrity in the field.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#field-implementation",
    "href": "field-methods/uvs_overview.html#field-implementation",
    "title": "Underwater Visual Surveys",
    "section": "Field Implementation",
    "text": "Field Implementation\n\nDive Team Coordination\nEffective dive team coordination is essential for collecting high-quality, consistent data. Teams typically include:\n\nDive Team Leader: Responsible for site selection, navigation, and completing the UVS Sites Fieldbook\nFish Counters: Conduct fish belt transects\nBenthic Divers: Conduct LPI, invertebrate counts, and coral recruit surveys\n\nTo minimize disturbance to fish communities, fish counters and benthic divers coordinate to swim in opposite directions. This prevents benthic survey activities from affecting fish behavior before they can be counted.\n\n\nExpedition Diving Schedule\nThe Pristine Seas team typically conducts three dives per day: - 2 morning dives (usually between 08:00-12:00) - 1 afternoon dive (usually between 14:00-16:00)\nThis schedule maximizes data collection efficiency while allowing adequate surface intervals and time for equipment maintenance and data entry between dives.\n\n\nSurvey Orchestration\nA typical survey follows this sequence:\n\nArrival and setup:\n\nMark surface location (GPS coordinates)\nSet anchor or mooring\nDeploy surface marker if needed\nTake YSI profiles\nTake surface water eDNA samples (when applicable)\n\nUnderwater implementation:\n\nTeam leader selects precise station locations\nDeploy transect tapes along consistent depth contour\nTeams establish separate but co-located transects for different survey components\nFish counters and benthic divers swim in opposite directions\nConduct fish surveys first to minimize disturbance effects\nComplete LPI on separate but nearby transects\nConduct invertebrate surveys\nComplete coral recruit surveys\nPhotograph the site and transects\n\nPost-dive procedures:\n\nTeam leader completes the UVS Sites Fieldbook\nReview and verify data sheets\nNote any protocol deviations or unusual observations",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#references",
    "href": "field-methods/uvs_overview.html#references",
    "title": "Underwater Visual Surveys",
    "section": "References",
    "text": "References\nFriedlander, A. M., Sandin, S. A., DeMartini, E. E., & Sala, E. (2010). Spatial patterns of the structure of reef fish assemblages at a pristine atoll in the central Pacific. Marine Ecology Progress Series, 410, 219-231.\nSala, E., & Giakoumi, S. (2018). No-take marine reserves are the most effective protected areas in the ocean. ICES Journal of Marine Science, 75(3), 1166-1168.\nSandin, S. A., Smith, J. E., DeMartini, E. E., Dinsdale, E. A., Donner, S. D., Friedlander, A. M., … & Sala, E. (2008). Baselines and degradation of coral reefs in the Northern Line Islands. PloS one, 3(2), e1548."
  },
  {
    "objectID": "field-methods/uvs_overview.html#site-selection-and-planning",
    "href": "field-methods/uvs_overview.html#site-selection-and-planning",
    "title": "Underwater Visual Surveys",
    "section": "Site Selection and Planning",
    "text": "Site Selection and Planning\nSites are selected to represent the range of habitats within the study area, with consideration for:\n\nHabitat representation: Major habitat types present in the region\nDepth zones: Ensuring coverage across all three depth strata\nExposure gradient: From protected to exposed locations\nConservation representativeness: Inclusion of potential conservation targets\nCommunity input: Local knowledge and areas of importance to communities\nAccessibility: Practical considerations for dive operations\n\n\nDocumentation\nFor each selected site, the team documents:\n\nPrecise GPS coordinates\nHabitat characteristics and topography\nPhotographic records of site conditions\nDepth measurements at each station\nExposure level and current conditions\nSite maps with station locations\n\nThe dive team leader maintains the UVS Sites Fieldbook, a critical document that serves as the master reference for all site metadata and survey information. This fieldbook ensures proper cross-referencing between datasets collected by different team members and includes verification of completed protocols.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#survey-components",
    "href": "field-methods/uvs_overview.html#survey-components",
    "title": "Overview",
    "section": "Survey Components",
    "text": "Survey Components\nThe Pristine Seas underwater visual survey framework integrates four complementary components:\n\nFish Belt Transects: Quantify fish diversity, abundance, and biomass\nLine Point Intercept (LPI): Assess benthic cover and composition\nInvertebrate Counts: Document mobile invertebrate abundance\nCoral Recruit Surveys: Measure coral recruitment and population dynamics\n\nThese components are conducted along the same depth strata but on separate transects that are co-located as closely as possible within the same habitat and site. This approach allows for comprehensive sampling of each ecosystem element.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#survey-structure",
    "href": "field-methods/uvs_overview.html#survey-structure",
    "title": "Overview",
    "section": "Survey Structure",
    "text": "Survey Structure\n\nSites\nEach underwater visual survey location is designated as a site. Sites form the primary organizational unit for our surveys and are carefully selected to represent the full range of marine environments within the study area.\nSite Selection Criteria:\n\nHabitat representation: Major habitat types present in the region (e.g., forereef, lagoon, backreef)\nExposure gradient: From protected/sheltered to exposed locations\nProtection status: Both inside and outside protected areas when applicable\nCommunity input: Locations identified by local knowledge as important\nAccessibility: Practical considerations for safe dive operations\n\n\n\nStations\nEach site contains stations at different depths to capture vertical zonation patterns. Typically, two depths are surveyed at each site and the specific depths surveyed depend on local bathymetry, habitat distribution, and research priorities. In some locations, only one depth strata may be present or accessible. In this cases, the team may double the sampling effort at the single station.\n\n\n\n\n\n\nStandard UVS depth strata\n\n\n\nEvery survey station is assigned to one of three standardized depth strata with corresponding suffixes that build the station label:\nDepth strata and suffixes:\n\nSupershallow (≤ 6 m) → 05m\n\nShallow (7–14 m) → 10m\n\nDeep (≥ 15 m) → 20m\n\nStation ID structure: [ISO3]_[YEAR]_uvs_[SITE]_[Depth_suffix]\nExamples:\n\nFirst survey of Fiji’s 2025 expedition at 5.8 m → FJI_2025_uvs_001_05m\nFirst survey of Fiji’s 2025 expedition at 12 m → FJI_2025_uvs_001_10m\n\nThis scheme ensures consistent stratification across all analyses, even with natural variation in survey depth.\n\n\n\n\nTransects\nAt each station, survey methods use multiple standardized transects at consistent depth contours to derive robust station averages. These function as pseudoreplicates rather than independent samples, improving precision and accounting for small-scale spatial variation. Detailed specifications are provided in each method’s dedicated section.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#field-operations",
    "href": "field-methods/uvs_overview.html#field-operations",
    "title": "Overview",
    "section": "Field Operations",
    "text": "Field Operations\nThe Pristine Seas underwater visual surveys involve careful coordination between multiple divers conducting complementary assessments at each site. This orchestrated approach maximizes data collection efficiency while maintaining scientific rigor and preventing interference between methods.\n\nDive Team\n\n\nFish Survey Team\n\n2 divers\nWork independently at each depth strata\nRotate depths between dives\n\n\n\nBenthic Survey Unit\n\n3 divers (LPI, Coral, Inverts/Recruits)\nWork as a coordinated unit across both strata\n\n\n\n\n\nSchedule\nThe typical expedition schedule includes three dives per day:\n\n2 morning dives (08:00-12:00)\n1 afternoon dive (14:00-16:00)\n\n\n\nChoreography\n\nSite preparation:\n\nDive boat positions at GPS coordinates\nEntry point marked with mooring or surface marker\nTeam conducts pre-dive briefing\nYSI profile taken and surface eDNA samples collected if applicable\n\nDescent sequence:\n\nTeam descends together to the deeper station and assess conditions\nIf workable, teams separate to respective survey areas/strata\n\nFish Survey:\n\nEach fish diver works at their assigned depth (2-3 transects)\nCollects photographic records of site and notable, hard to id species\nNotes noteworhtly off transect observations\n\nBenthic Survey:\n\nTeam descends together to the 20m depth stratum\nIf eDNA collection is planned, recruit/invert diver collects water samples first\n50m transect line deployed by benthic diver.\nBenthic diver (LPI):\n\nStarts at 50m mark\nWorks toward 0m recording points every 20cm\n\nCoral diver:\n\nStarts at 0m mark\nWorks toward 50m identifying coral species at points\n\nRecruit/invert diver:\n\nStarts at 45m mark with quadrat surveys (every 5m)\nAfter completing quadrats, stashes equipment\nReturns along transect recording invertebrates\n\nCompletion and transition:\n\nDivers meet at transect end\nTeam recovers transect reel and equipment\nGroup ascends together to 10m depth stratum\nEntire process repeated at 10m depth\n\n\nExit coordination:\n\nAll divers return to mooring/entry point\nTeam conducts safety stop together\nSurfaces at initial entry point\n\nPost-dive procedures:\n\nTeam leader completes site documentation\nEach diver completes method-specific datasheets\nEquipment prepared for next dive\nData entered into digital format at the end of the day.\n\n\nThis coordinated approach ensures that comprehensive ecosystem data is collected at each station while maintaining methodological consistency and diver safety.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#documentation-and-quality-control",
    "href": "field-methods/uvs_overview.html#documentation-and-quality-control",
    "title": "Overview",
    "section": "Documentation and Quality Control",
    "text": "Documentation and Quality Control\n\nUVS Sites Fieldbook\nThe UVS Sites Fieldbook is the primary reference for recording site-specific information and survey activities during expeditions. Maintained by the dive team lead, it serves as the authoritative source for cross-referencing UVS datasets and ensuring data consistency.\nDaily records include:\n\nLocation Details: Region, subregion, locality, site name\n\nAccurate Coordinates: GPS coordinates (WGS84)\n\nSite Conditions: Habitat type and exposure level\n\nProtocol Completion: Survey methods executed and any deviations noted\n\nField Notes: Notable observations, incidents, and contextual informatio\n\nAll habitat types and exposure levels must be recorded using the controlled vocabulary specified below. This standardization is critical for understanding ecological patterns, enabling comparisons across sites, and assessing habitat-specific community structure and condition.\n\n\n\n\n\n\nControlled vocabulary\n\n\n\nhabitat\n\nfore reef — Outer reef slope exposed to ocean swell.\nback reef — Sheltered zone behind the reef crest\n\nfringing reef — Reef growing directly from the shoreline\n\npatch reef — Isolated reef outcrop within a lagoon or sandy area\n\nreef flat — Shallow, flat reef section, often exposed at low tide\n\nchannel — Natural break or passage between reef structures\n\nseagrass — Vegetated, soft-bottom habitat dominated by seagrasses\n\nrocky reef — Reef formed by consolidated rock\n\nother — Habitat not captured by the above categories\n\nexposure\n\nwindward — Facing prevailing winds and swell\n\nleeward — Sheltered from prevailing winds\n\nlagoon — Within an enclosed or semi-enclosed reef lagoon\n\nother — Exposure type not described above\n\n\n\n\n\nMethod - specific fielbooks\n\n\nPhotographic records\n\n\nQuality Assurance Procedures\nTo maintain data integrity across all UVS methods, we implement these key quality control measures:\nSame-Day Data Entry\nRecord all observations immediately after diving while details remain fresh and accurate\nDaily QAQC Review\nSave data to the ship’s NAS for quality checks, including mapping of survey sites to check accuracy and inform planning\nSpecies Verification\nConfirm identifications using photographic evidence and our physical and digital reference library\nTaxonomic Standardization\nMinimize taxonomic errors by using the team’s taxonomic reference list for consistent species identification and database linkage\nSource Documentation\nArchive original field datasheets securely for future reference and verification\nCross-Referenced Records\nEnsure consistency by validating all method-specific data against the UVS Sites Fieldbook",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html",
    "href": "field-methods/benthic_lpi.html",
    "title": "Line Point Intercept",
    "section": "",
    "text": "The Line Point Intercept (LPI) method is a fundamental component of Pristine Seas underwater visual surveys, providing quantitative data on benthic community composition and substrate cover. This method documents the relative abundance of key benthic categories, including corals, algae, and other sessile organisms, as well as abiotic substrate types.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#introduction",
    "href": "field-methods/benthic_lpi.html#introduction",
    "title": "Line Point Intercept",
    "section": "",
    "text": "The Line Point Intercept (LPI) method is a fundamental component of Pristine Seas underwater visual surveys, providing quantitative data on benthic community composition and substrate cover. This method documents the relative abundance of key benthic categories, including corals, algae, and other sessile organisms, as well as abiotic substrate types.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#method-overview",
    "href": "field-methods/benthic_lpi.html#method-overview",
    "title": "Line Point Intercept",
    "section": "Method Overview",
    "text": "Method Overview\nThe LPI method involves recording the benthic organisms or substrate types that occur directly beneath points at regular intervals along a transect line. This approach provides an unbiased estimate of percent cover for different benthic categories.\n\nKey Features\n\nStandardized points: Data collected at fixed intervals (20 cm)\nRepresentative sampling: Points distributed evenly along the entire transect\nObjective assessment: Only what lies directly under each point is recorded\nTaxonomic resolution: Identification to the lowest practical taxonomic level\nDivision of labor: Separate divers for coral and other benthic identifications",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#field-implementation",
    "href": "field-methods/benthic_lpi.html#field-implementation",
    "title": "Line Point Intercept",
    "section": "Field Implementation",
    "text": "Field Implementation\nThe LPI method requires two specialized divers working in tandem:\n\nBenthic diver: Identifies all algae, non-coral invertebrates, and abiotic substrates at each point. When a point lands on coral, the benthic diver marks it as “Hard coral” (or “Hard coral - bleached”) without species identification.\nCoral diver: Focuses specifically on identifying all corals to species level at points previously marked as “Hard coral” by the benthic diver.\n\nThis division of labor ensures both broad coverage of all substrate types and precise taxonomic resolution for corals.\n\n\n\n\n\n\nLPI Transect Specifications\n\n\n\n\nLength: 50 meters (Note: transects may be shorter due to time or decompression constraints)\nDirection: Parallel to shoreline\nDepth strata: Constant (±1 m) standard depth strata (~5, 10 or 20 m)\nPoints: Sampled every 20 cm (250 points total)\nSections: Transects are divided into sections (5 of 10 m each)\n\n\n\n\nData Collection Procedure\n\nTransect deployment:\n\nDeploy transect tape parallel to shoreline\nMaintain consistent depth throughout\nSecure ends to maintain straight line\n\nPoint sampling:\n\nSample at 20 cm intervals along the transect (250 points total)\nRecord what lies directly beneath each point\nBenthic diver identifies all non-coral points to lowest taxonomic level\nCoral diver identifies coral points to species level\n\nBleaching assessment:\n\nFor hard corals: differentiate between healthy, bleaching, and dead colonies\nFor soft corals: distinguish bleached and non-bleached colonies\n\nPhoto documentation:\n\nTake overview photo of transect\nPhotograph representative points\nDocument unusual or unidentified organisms\n\nExplore:\n\nRoam the station if time allows\nDocument any notable off-transect taxa or observations",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#data-categories",
    "href": "field-methods/benthic_lpi.html#data-categories",
    "title": "Benthic Line Point Intercept",
    "section": "Data Categories",
    "text": "Data Categories\n\nBenthic Classification Scheme\nPristine Seas uses a hierarchical classification system for benthic organisms and substrate types:\n\n\nCoral Categoriess",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#data-processing-and-analysis",
    "href": "field-methods/benthic_lpi.html#data-processing-and-analysis",
    "title": "Benthic Line Point Intercept",
    "section": "Data Processing and Analysis",
    "text": "Data Processing and Analysis\n\nData Entry\nLPI data are entered into standardized digital formats:\n\n\nQAQC\n\n\nKey metrics\nStandard metrics calculated from LPI data include:\n\nPercent cover by category: Proportion of points occupied by each benthic category\nCoral:algal ratio: Ratio of coral cover to algal cover (HC/(MA+TA))\nBleaching prevalence: Proportion of coral points showing signs of bleaching\nCoral taxonomic diversity: Number and relative abundance of coral species\nBenthic community composition: Multivariate analysis of overall community structure\n\n\n\nOutput tables",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#quality-control",
    "href": "field-methods/benthic_lpi.html#quality-control",
    "title": "Benthic Line Point Intercept",
    "section": "Quality Control",
    "text": "Quality Control\n\nField Quality Control\n\nCalibration exercises before expeditions\nCross-checking between divers when uncertain\nPhotographic verification of unusual or difficult identifications\nRegular monitoring of inter-observer variability\n\n\n\nData Entry Quality Control\n\nUse of standardized data entry templates with validation rules\nDouble-checking of entered data against field sheets\nVerification of unusual cover values (e.g., &gt;50% of a single category)\nCross-checking against photo documentation",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#integration-with-other-methods",
    "href": "field-methods/benthic_lpi.html#integration-with-other-methods",
    "title": "Benthic Line Point Intercept",
    "section": "Integration with Other Methods",
    "text": "Integration with Other Methods\nLPI data are integrated with other survey methods to provide a comprehensive ecosystem assessment:\n\nFish surveys: Relating fish abundance to benthic habitat characteristics\nInvertebrate counts: Assessing relationships between mobile invertebrates and substrate\nCoral recruitment: Correlating recruit density with adult coral cover and substrate availability\nEnvironmental data: Analyzing benthic composition in relation to physical parameters",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#adaptations-for-special-circumstances",
    "href": "field-methods/benthic_lpi.html#adaptations-for-special-circumstances",
    "title": "Benthic Line Point Intercept",
    "section": "Adaptations for Special Circumstances",
    "text": "Adaptations for Special Circumstances\nThe LPI protocol can be modified to address specific research questions or environmental conditions:",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#references",
    "href": "field-methods/benthic_lpi.html#references",
    "title": "Line Point Intercept",
    "section": "References",
    "text": "References\nCoral Reef Alliance. (2024). Coral Bleaching On-Site Monitoring Tools.\nDarling ES, Alvarez-Filip L, Oliver TA, McClanahan TR, Côté IM. (2012). Evaluating life-history strategies of reef corals from species traits. Ecology Letters, 15(12), 1378-1386.\nFacon, M., et al. (2016). A comparative study of the accuracy and effectiveness of Line and Point Intercept Transect methods for coral reef monitoring in the southwestern Indian Ocean islands. Ecological Indicators, 60, 1045-1055.\nKuo, C-Y., et al. (2022). Fine intervals are required when using point intercept transects to assess coral reef status. Frontiers in Marine Science, 9, 795512.\nLeujak, W., & Ormond, R.F.G. (2007). Comparative accuracy and efficiency of six coral community survey methods. Journal of Experimental Marine Biology and Ecology, 351(1-2), 168-187.\nVallès, H., et al. (2019). Switching between standard coral reef benthic monitoring protocols is complicated: proof of concept. PeerJ, 7, e8167.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#key-parameters",
    "href": "field-methods/benthic_lpi.html#key-parameters",
    "title": "Benthic Line Point Intercept",
    "section": "Key Parameters",
    "text": "Key Parameters\n\n\n\n\n\n\n\n\nParameter\nSpecification\nNotes\n\n\n\n\nLength\n50 meters\nSingle continuous transect\n\n\nDirection\nParallel to shoreline\nFollowing depth contour\n\n\nDepth strata\nConstant (±1 m) standard depth strata (~5, 10 or 20 m)\nMaintain consistency throughout transect\n\n\nSampling interval\nEvery 20 cm\n250 points total per transect\n\n\nData organization\n5 sections of 10 m each\nSections serve as pseudoreplicates\n\n\n\nImportant note: At deeper stations (20m), transects may be shortened to 30m due to decompression limits. In these cases, adjust the sampling design accordingly while maintaining the same methodological approach.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#benthic-categories",
    "href": "field-methods/benthic_lpi.html#benthic-categories",
    "title": "Benthic Line Point Intercept",
    "section": "Benthic Categories",
    "text": "Benthic Categories\n\nHierarchical Classification System\nThe Pristine Seas benthic classification follows a hierarchical approach to ensure both field-level detail and analytical standardization:\n\n\nCode\ngraph TD\n    classDef fieldObs fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Observation&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Minimum Acceptable Taxonomic Resolution&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldObs\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\ngraph TD\n    classDef fieldObs fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Observation&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Minimum Acceptable Taxonomic Resolution&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldObs\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\n\n\n\nField observations (e.g., “blue sponge tall”): Initial descriptions recorded by divers\nMorphotaxon (e.g., “Haliclona sp. blue”): Consolidation of field observations\nMinimum acceptable taxonomic resolution (e.g., “Haliclona sp.”): Confidence-based taxonomic level\nBenthic functional category: Ecological grouping for analysis\n\n\n\nBenthic Functional Categories\nThe following standardized functional categories are used for analysis and visualization:\n\n\n\nHard Coral Scleractinian corals with calcium carbonate skeletons Examples: Acropora spp., Porites spp., Montastraea spp.\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae Examples: Porolithon spp., Lithophyllum spp., Hydrolithon spp.\n\n\n\nCyanobacteria Photosynthetic bacterial mats Examples: Lyngbya spp., Oscillatoria spp., Symploca spp.\n\n\n\nSoft Coral Non-reef building octocorals Examples: Sinularia spp., Sarcophyton spp., Lobophytum spp.\n\n\n\nSponges Porifera of various morphologies Examples: Xestospongia spp., Haliclona spp., Cliona spp.\n\n\n\nSediment/Rubble/Barren Abiotic substrates and bare surfaces Examples: Sand, coral rubble, bare rock\n\n\n\nEncrusting Algae Non-coralline encrusting macroalgae Examples: Peyssonnelia spp., Lobophora spp., Ralfsia spp.\n\n\n\nErect Algae Upright macroalgae with distinct structure Examples: Sargassum spp., Turbinaria spp., Halimeda spp.\n\n\n\nTurf Low-growing filamentous algal assemblages Examples: Mixed filamentous turf, cyanobacterial turf, red turf\n\n\n\nOther Organisms that don’t fit main categories Examples: Ascidians, bryozoans, hydroids\n\n\n\n\n\nBleaching Classification\nFor bleaching assessments, corals are further categorized by their condition:\n\n\n\n\n\n\nBleaching Status Categories\n\n\n\nHard corals:\n\nHard coral: Healthy scleractinian coral with normal coloration\nHard coral - bleached: Actively bleaching with visible loss of zooxanthellae\nHard coral - dead: Recently dead, post-bleaching mortality\n\nSoft corals:\n\nSoft coral: Healthy octocoral with normal coloration\nSoft coral - bleached: Visibly bleached octocoral\nSoft coral - dead: Recently dead octocoral with visible structure\n\n\n\n\n\nCoral Ecological Classification\nHard corals are additionally classified according to the Darling et al. (2012) framework based on life history strategies:\n\n\n\nCompetitive Fast-growing, structurally complex corals that dominate under favorable conditions Examples: Acropora palmata (elkhorn), Acropora cervicornis (staghorn), Acropora hyacinthus (table) Morphologies: Branching, tabular, corymbose\n\n\n\n\n\nWeedy Small, short-lived corals with high reproductive output and limited competitive ability Examples: Pocillopora damicornis, Stylophora pistillata, Seriatopora hystrix Morphologies: Small branching, digitate\n\n\n\n\n\n\n\n\n\nStress-Tolerant Slow-growing, long-lived massive corals resistant to environmental stressors Examples: Porites lobata, Orbicella annularis, Siderastrea siderea Morphologies: Massive, encrusting\n\n\n\n\n\nGeneralist Moderate growth and reproduction with intermediate stress tolerance Examples: Montastraea cavernosa, Pavona spp., Galaxea fascicularis Morphologies: Massive, foliose, solitary\n\n\n\n\n\nCoral Morphology\nHard coral morphologies are documented to relate form to function:\n\n\n\n\n\n\nCoral Morphological Categories\n\n\n\n\nEncrusting: Growing flat against substrate (e.g., Montipora spumosa)\nTabular: Horizontal plate-like growth (e.g., Acropora hyacinthus)\nBranching: Tree-like with thin branches (e.g., Acropora muricata)\nMassive: Boulder-like, robust growth (e.g., Porites lobata)\nSolitary: Individual polyps (e.g., Fungia fungites)\nFoliose: Leaf-like or whorl structure (e.g., Turbinaria reniformis)\nDigitate: Finger-like branches (e.g., Pocillopora meandrina)\nCorymbose: Table-like with branchlets (e.g., Acropora cytherea)",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#references-1",
    "href": "field-methods/benthic_lpi.html#references-1",
    "title": "Benthic Line Point Intercept",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#benthic-classes",
    "href": "field-methods/benthic_lpi.html#benthic-classes",
    "title": "Benthic Line Point Intercept",
    "section": "Benthic classes",
    "text": "Benthic classes\n\nHierarchical Classification System\nThe Pristine Seas benthic classification follows a hierarchical approach to ensure both field-level detail and analytical standardization:\nField morphotaxa aew consolidated to their lowest defensible taxonomic rank based on authoritative references\n\n\nCode\ngraph TD\n    classDef fieldObs fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Observation&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Minimum Acceptable Taxonomic Resolution&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldObs\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\ngraph TD\n    classDef fieldObs fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Observation&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Minimum Acceptable Taxonomic Resolution&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldObs\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\n\n\n\nField observations (e.g., “blue sponge tall”): Initial descriptions recorded by divers\nMorphotaxon (e.g., “Haliclona sp. blue”): Consolidation of field observations\nMinimum acceptable taxonomic resolution (e.g., “Haliclona sp.”): Confidence-based taxonomic level\nBenthic functional category: Ecological grouping for analysis\n\n\n\nBenthic Functional Categories\nThe following standardized functional categories are used for analysis and visualization:\n\n\n\nHard Coral Scleractinian corals with calcium carbonate skeletons Examples: Acropora spp., Porites spp., Montastraea spp.\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae Examples: Porolithon spp., Lithophyllum spp., Hydrolithon spp.\n\n\n\nCyanobacteria Photosynthetic bacterial mats Examples: Lyngbya spp., Oscillatoria spp., Symploca spp.\n\n\n\nSoft Coral Non-reef building octocorals Examples: Sinularia spp., Sarcophyton spp., Lobophytum spp.\n\n\n\nSponges Porifera of various morphologies Examples: Xestospongia spp., Haliclona spp., Cliona spp.\n\n\n\nSediment/Rubble/Barren Abiotic substrates and bare surfaces Examples: Sand, coral rubble, bare rock\n\n\n\nEncrusting Algae Non-coralline encrusting macroalgae Examples: Peyssonnelia spp., Lobophora spp., Ralfsia spp.\n\n\n\nErect Algae Upright macroalgae with distinct structure Examples: Sargassum spp., Turbinaria spp., Halimeda spp.\n\n\n\nTurf Low-growing filamentous algal assemblages Examples: Mixed filamentous turf, cyanobacterial turf, red turf\n\n\n\nOther Organisms that don’t fit main categories Examples: Ascidians, bryozoans, hydroids\n\n\n\n\n\nBleaching Classification\nFor bleaching assessments, corals are further categorized by their condition:\n\n\n\n\n\n\nBleaching Status Categories\n\n\n\nHard corals:\n\nHard coral: Healthy scleractinian coral with normal coloration\nHard coral - bleached: Actively bleaching with visible loss of zooxanthellae\nHard coral - dead: Recently dead, post-bleaching mortality\n\nSoft corals:\n\nSoft coral: Healthy octocoral with normal coloration\nSoft coral - bleached: Visibly bleached octocoral\nSoft coral - dead: Recently dead octocoral with visible structure\n\n\n\n\n\nCoral Ecological Classification\nHard corals are additionally classified according to the Darling et al. (2012) framework based on life history strategies:\n\n\n\nCompetitive Fast-growing, structurally complex corals that dominate under favorable conditions Examples: Acropora palmata (elkhorn), Acropora cervicornis (staghorn), Acropora hyacinthus (table) Morphologies: Branching, tabular, corymbose\n\n\n\n\n\nWeedy Small, short-lived corals with high reproductive output and limited competitive ability Examples: Pocillopora damicornis, Stylophora pistillata, Seriatopora hystrix Morphologies: Small branching, digitate\n\n\n\n\n\n\n\n\n\nStress-Tolerant Slow-growing, long-lived massive corals resistant to environmental stressors Examples: Porites lobata, Orbicella annularis, Siderastrea siderea Morphologies: Massive, encrusting\n\n\n\n\n\nGeneralist Moderate growth and reproduction with intermediate stress tolerance Examples: Montastraea cavernosa, Pavona spp., Galaxea fascicularis Morphologies: Massive, foliose, solitary\n\n\n\n\n\nCoral Morphology\nHard coral morphologies are documented to relate form to function:\n\n\n\n\n\n\nCoral Morphological Categories\n\n\n\n\nEncrusting: Growing flat against substrate (e.g., Montipora spumosa)\nTabular: Horizontal plate-like growth (e.g., Acropora hyacinthus)\nBranching: Tree-like with thin branches (e.g., Acropora muricata)\nMassive: Boulder-like, robust growth (e.g., Porites lobata)\nSolitary: Individual polyps (e.g., Fungia fungites)\nFoliose: Leaf-like or whorl structure (e.g., Turbinaria reniformis)\nDigitate: Finger-like branches (e.g., Pocillopora meandrina)\nCorymbose: Table-like with branchlets (e.g., Acropora cytherea)",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#taxonomic-resolution-model",
    "href": "field-methods/benthic_lpi.html#taxonomic-resolution-model",
    "title": "Benthic Line Point Intercept",
    "section": "Taxonomic Resolution Model",
    "text": "Taxonomic Resolution Model\nThe Pristine Seas LPI method employs world-class scientific divers who typically identify organisms to species level immediately. However, for challenging identifications, we use a structured taxonomic resolution model that ensures scientific rigor throughout the identification process.\n\n\nCode\ngraph TD\n    classDef fieldName fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Name&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Lowest Defensible Taxonomic Rank&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldName\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\ngraph TD\n    classDef fieldName fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Name&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Lowest Defensible Taxonomic Rank&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldName\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\n\n\nClassification Levels\nOur taxonomic resolution progresses through four distinct levels:\n\nField Names: When species-level identification isn’t immediately possible, divers use descriptive temporary placeholders based on distinguishing characteristics. Example: “blue branching coral,” “tall green algae,” “orange encrusting sponge”\nMorphotaxa: Field names are refined into preliminary taxonomic units that combine formal taxonomy with distinguishing field characteristics. This process begins onboard the expedition vessel and evolves as divers gain familiarity with local taxa. Example: “Acropora sp. blue,” “Halimeda sp. tall,” “Clathria sp. orange”\nLowest Defensible Taxonomic Rank: The lowest taxonomic level that can be scientifically defended based on visual identification and available evidence. Example: “Acropora sp.,” “Halimeda sp.,” “Porifera”\nBenthic Functional Categories: Classification of taxa into ecological functional groups for ecosystem-level analyses. These are derived from standardized taxonomy reference lists after the expedition. Example: “Hard Coral,” “Erect Algae,” “Sponges”\n\n\n\n\n\n\n\nTaxonomic Resolution Process\n\n\n\nProgressive Identification Workflow\n\nDuring dives\n\nDivers identify organisms to species level when possible\nFor challenging taxa, descriptive field names are used as placeholders\n\nOnboard processing\n\nConsolidation into morphotaxa begins immediately onboard:\n\nDivers review photographs and compare observations\nTaxonomic knowledge improves progressively throughout expedition\nField guides and reference materials guide identifications\n\n\nPost-expedition refinement\n\nFinal taxonomic processing using expedition reference taxonomy lists:\n\nMorphotaxa → Lowest defensible taxonomic rank\nTaxonomic rank → Functional group\nFor corals: Addition of morphology and life history classifications\n\n\n\nThis progressive approach maximizes identification accuracy while maintaining scientific integrity.\n\n\n\n\nBenthic Functional Categories\nThe following standardized functional categories are used for analysis and visualization:\n\n\n\nHard Coral Scleractinian corals with calcium carbonate skeletons Examples: Acropora spp., Porites spp.\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae Examples: Porolithon spp., Lithophyllum spp., Hydrolithon spp.\n\n\n\nCyanobacteria Photosynthetic bacterial mats Examples: Lyngbya spp., Oscillatoria spp., Symploca spp.\n\n\n\nSoft Coral Non-reef building octocorals Examples: Sinularia spp., Sarcophyton spp., Lobophytum spp.\n\n\n\nSponges Porifera of various morphologies Examples: Xestospongia spp., Haliclona spp., Cliona spp.\n\n\n\nEncrusting Algae Non-coralline encrusting macroalgae Examples: Peyssonnelia spp., Lobophora spp., Ralfsia spp.\n\n\n\nErect Algae Upright macroalgae with distinct structure Examples: Sargassum spp., Turbinaria spp., Halimeda spp.\n\n\n\nTurf Low-growing filamentous algal assemblages Examples: Mixed filamentous turf, cyanobacterial turf, red turf\n\n\n\nOther Organisms that don’t fit main categories Examples: Ascidians, bryozoans, hydroids\n\n\n\nSediment/Rubble/Barren Abiotic substrates and bare surfaces Examples: Sand, coral rubble, bare rock\n\n\n\n\n\nHard Coral Classification\nPristine Seas classifies hard corals using complementary systems that enable comprehensive analysis of community structure, ecological function, and resilience potential across survey sites.\n\nLife History Strategies\nCoral species exhibit distinct life history strategies that reflect evolutionary adaptations to different environmental conditions. Darling et al. (2012) identified four globally consistent strategies across 143 coral species through hierarchical clustering and random forests analyses, primarily distinguished by colony morphology, growth rate, and reproductive mode. These strategies help predict species responses to disturbances and inform conservation approaches in the rapidly changing marine environment.\n\nCompetitiveWeedyStress-TolerantGeneralist\n\n\nTraits: Fast growth (&gt;15 cm/year), broadcast spawning, large colonies with low skeletal density. Dominate favorable environments and outcompete others for space.\nDisturbance tolerance: Vulnerable to bleaching and physical damage with poor recovery capacity.\nExamples: Acropora palmata, A. cervicornis, Pocillopora elegans\nMorphologies: Branching, plating, corymbose forms creating complex habitats.\n\n\nTraits: Variable growth, brooding reproduction, high reproductive output, small colonies (&lt;20cm). Pioneer species colonizing disturbed areas.\nDisturbance tolerance: Moderate bleaching susceptibility but quick recovery through rapid recruitment and effective dispersal.\nExamples: Pocillopora damicornis, Stylophora pistillata, Seriatopora hystrix\nMorphologies: Small branching, digitate forms establishing rapidly on available substrate.\n\n\nTraits: Slow growth (&lt;5 cm/year), broadcast spawning, conservative energy use, high skeletal density. Long-lived colonies persisting in marginal environments.\nDisturbance tolerance: Resistant to acute stressors, withstand higher temperatures, slow but persistent recovery.\nExamples: Porites lobata, Orbicella annularis, Siderastrea siderea\nMorphologies: Massive, boulder, encrusting forms providing reef framework stability.\n\n\nTraits: Moderate growth (5-15 cm/year), mixed reproduction strategies, balanced resource allocation. Adaptable across environmental gradients.\nDisturbance tolerance: Intermediate thermal tolerance with moderate recovery capacity and variable stress responses.\nExamples: Diploria labyrinthiformis, Pavona spp., Galaxea fascicularis\nMorphologies: Massive, foliose, meandroid forms with moderate complexity.\n\n\n\n\n\nMorphology\nCoral morphology represents the physical structure and growth form that coral colonies develop, directly influencing their ecological function and response to environmental stressors. These distinct growth forms are key determinants in coral life history strategies and provide important insights into reef structural complexity, habitat provision, and resilience potential.\n\n\nBranching\n\nTree-like with thin branchese.g., Acropora muricata\n\n\n\nTabular\n\nHorizontal plate-like growthe.g., Acropora hyacinthus\n\n\n\nMassive\n\nBoulder-like, robust growthe.g., Porites lobata\n\n\n\nEncrusting\n\nGrowing flat against substratee.g., Montipora spumosa\n\n\n\nFoliose\n\nLeaf-like or whorl structuree.g., Turbinaria reniformis\n\n\n\nSolitary\n\nIndividual polypse.g., Fungia fungites\n\n\n\nDigitate\n\nFinger-like branchese.g., Pocillopora meandrina\n\n\n\nCorymbose\n\nTable-like with branchletse.g., Acropora cytherea",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#taxonomic-resolution",
    "href": "field-methods/benthic_lpi.html#taxonomic-resolution",
    "title": "Line Point Intercept",
    "section": "Taxonomic Resolution",
    "text": "Taxonomic Resolution\nThe Pristine Seas LPI method employs world-class scientific divers who typically identify organisms to species or genus level immediately. However, for challenging identifications, we use a structured taxonomic resolution model that ensures scientific rigor throughout the identification process.\n\n\nCode\ngraph TD\n    classDef fieldName fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Name&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Lowest Defensible Taxonomic Rank&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldName\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\ngraph TD\n    classDef fieldName fill:#F8F9FA,stroke:#DEE2E6,stroke-width:2px,color:#000000,font-size:14px\n    classDef morphotaxon fill:#E9EDF9,stroke:#6C8EBF,stroke-width:2px,color:#000000,font-size:14px\n    classDef minTaxon fill:#D4E4F9,stroke:#3F75BF,stroke-width:2px,color:#000000,font-size:14px\n    classDef funcCat fill:#004165,stroke:#002E48,stroke-width:2px,color:#FFFFFF,font-size:14px\n    \n    A[Field Name&lt;br&gt;'blue branching coral'] --&gt; B[Morphotaxon&lt;br&gt;'Acropora sp. blue']\n    B --&gt; C[Lowest Defensible Taxonomic Rank&lt;br&gt;'Acropora sp.']\n    C --&gt; D[Benthic Functional Category&lt;br&gt;'Hard Coral']\n    \n    class A fieldName\n    class B morphotaxon\n    class C minTaxon\n    class D funcCat\n    \n    style D fill:#EA9E8D,stroke:#D87F6A,stroke-width:2px,color:#000000\n\n\n\n\n\n\nOur taxonomic resolution progresses through four distinct levels:\n\nField Names: When species-level identification isn’t immediately possible, divers use descriptive temporary placeholders based on distinguishing characteristics.\nExample: “blue branching coral,” “tall green algae,” “orange encrusting sponge”\nMorphotaxa: Field names are consolidated into taxonomic units that combine formal taxonomy with distinguishing field characteristics. This process begins onboard the expedition vessel and evolves as divers gain familiarity with local taxa.\nExample: “Acropora sp. blue,” “Halimeda sp. tall,” “Clathria sp. orange”\nLowest Defensible Taxonomic Rank: Morphotaxa are mapped to the lowest taxonomic level that can be scientifically defended based on available evidence.\nExample: “Acropora sp.,” “Halimeda sp.,” “Porifera”\nBenthic Functional Categories: Taxonomic ranks are classified into ecological functional groups for ecosystem-level analyses. These are derived from standardized taxonomy reference lists.\nExample: “Hard Coral,” “Erect Algae,” “Sponges”\n\n\n\n\n\n\n\nTaxonomic Identification Workflow\n\n\n\nA Progressive Workflow\n\nDuring dives\n\nDivers identify organisms to species level when possible\nFor challenging taxa, descriptive field names are used as placeholders\n\nOnboard processing\n\nConsolidation into morphotaxa begins immediately onboard:\n\nDivers review photographs and compare observations\nTaxonomic knowledge improves progressively throughout expedition\nField guides and reference materials guide identifications\n\n\nPost-expedition refinement\n\nFinal taxonomic processing using expedition reference taxonomy lists:\n\nMorphotaxa → Lowest defensible taxonomic rank\nTaxonomic rank → Functional group\nFor corals: Addition of morphology and life history classifications",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#functional-categories",
    "href": "field-methods/benthic_lpi.html#functional-categories",
    "title": "Line Point Intercept",
    "section": "Functional Categories",
    "text": "Functional Categories\nWe use the following standardized functional categories for analysis and visualization:\n\n\n\nHard Coral Scleractinian corals with calcium carbonate skeletons Examples: Acropora spp., Porites spp.\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae Examples: Porolithon spp., Lithophyllum spp., Hydrolithon spp.\n\n\n\nCyanobacteria Photosynthetic bacterial mats Examples: Lyngbya spp., Oscillatoria spp., Symploca spp.\n\n\n\nSoft Coral Non-reef building octocorals Examples: Sinularia spp., Sarcophyton spp., Lobophytum spp.\n\n\n\nSponges Porifera of various morphologies Examples: Xestospongia spp., Haliclona spp., Cliona spp.\n\n\n\nEncrusting Algae Non-coralline encrusting macroalgae Examples: Peyssonnelia spp., Lobophora spp., Ralfsia spp.\n\n\n\nErect Algae Upright macroalgae with distinct structure Examples: Sargassum spp., Turbinaria spp., Halimeda spp.\n\n\n\nTurf Low-growing filamentous algal assemblages Examples: Mixed filamentous turf, cyanobacterial turf, red turf\n\n\n\nOther Organisms that don’t fit main categories Examples: Ascidians, bryozoans, hydroids\n\n\n\nSediment/Rubble/Barren Abiotic substrates and bare surfaces Examples: Sand, coral rubble, bare rock\n\n\n\n\nHard Corals\nHard corals are classified using complementary systems that enable comprehensive analysis of community structure, ecological function, and resilience potential across survey sites.\n\nLife History Strategies\nCoral species exhibit distinct life history strategies that reflect evolutionary adaptations to different environmental conditions. We map our coral taxa to the four strategies proposed by Darling et al. (2012) primarily distinguished by colony morphology, growth rate, and reproductive mode. These strategies help predict species responses to disturbances and inform conservation approaches in the rapidly changing marine environment.\n\nCompetitiveWeedyStress-TolerantGeneralist\n\n\nTraits\n\nFast growth, broadcast spawning, large colonies with low skeletal density.\nDominate favorable environments and outcompete others for space.\n\nDisturbance tolerance: Vulnerable to bleaching and physical damage with poor recovery capacity.\nExamples: Acropora palmata, A. cervicornis, Pocillopora elegans\nMorphologies: Branching, plating, corymbose forms creating complex habitats.\n\n\nTraits:\n\nVariable growth, brooding reproduction, high reproductive output, small colonies (&lt;20cm).\nPioneer species colonizing disturbed areas.\n\nDisturbance tolerance: Moderate bleaching susceptibility but quick recovery through rapid recruitment and effective dispersal.\nExamples: Pocillopora damicornis, Stylophora pistillata, Seriatopora hystrix\nMorphologies: Small branching, digitate forms establishing rapidly on available substrate.\n\n\nTraits:\n\nSlow growth (&lt;5 cm/year), broadcast spawning, conservative energy use, high skeletal density.\nLong-lived colonies persisting in marginal environments.\n\nDisturbance tolerance: Resistant to acute stressors, withstand higher temperatures, slow but persistent recovery.\nExamples: Porites lobata, Orbicella annularis, Siderastrea siderea\nMorphologies: Massive, boulder, encrusting forms providing reef framework stability.\n\n\nTraits:\n\nModerate growth (5-15 cm/year), mixed reproduction strategies, balanced resource allocation.\nAdaptable across environmental gradients.\n\nDisturbance tolerance: Intermediate thermal tolerance with moderate recovery capacity and variable stress responses.\nExamples: Diploria labyrinthiformis, Pavona spp., Galaxea fascicularis\nMorphologies: Massive, foliose, meandroid forms with moderate complexity.\n\n\n\n\n\nMorphology\nCoral morphology represents the physical structure and growth form that coral colonies develop, directly influencing their ecological function and response to environmental stressors. These distinct growth forms are key determinants in coral life history strategies and provide important insights into reef structural complexity, habitat provision, and resilience potential.\n\n\nBranching\n\nTree-like with thin branchese.g., Acropora muricata\n\n\n\nTabular\n\nHorizontal plate-like growthe.g., Acropora hyacinthus\n\n\n\nMassive\n\nBoulder-like, robust growthe.g., Porites lobata\n\n\n\nEncrusting\n\nGrowing flat against substratee.g., Montipora spumosa\n\n\n\nFoliose\n\nLeaf-like or whorl structuree.g., Turbinaria reniformis\n\n\n\nSolitary\n\nIndividual polypse.g., Fungia fungites\n\n\n\nDigitate\n\nFinger-like branchese.g., Pocillopora meandrina\n\n\n\nCorymbose\n\nTable-like with branchletse.g., Acropora cytherea",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#adaptations",
    "href": "field-methods/benthic_lpi.html#adaptations",
    "title": "Benthic Line Point Intercept",
    "section": "Adaptations",
    "text": "Adaptations\nThe LPI protocol can be modified to address specific research questions or environmental conditions:",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#data-pipeline",
    "href": "field-methods/benthic_lpi.html#data-pipeline",
    "title": "Benthic Line Point Intercept",
    "section": "Data Pipeline",
    "text": "Data Pipeline\n\nData Entry\nLPI data are entered into standardized digital formats:\n\n\nProcessing QA/QC\n\n\nExploratory Data Analyses\nStandard metrics calculated from LPI data include:\n\nPercent cover by category: Proportion of points occupied by each benthic category\nCoral:algal ratio: Ratio of coral cover to algal cover (HC/(MA+TA))\nBleaching prevalence: Proportion of coral points showing signs of bleaching\nCoral taxonomic diversity: Number and relative abundance of coral species\nBenthic community composition: Multivariate analysis of overall community structure\n\n\n\nOutputs and DB ingestion",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#data-processing",
    "href": "field-methods/benthic_lpi.html#data-processing",
    "title": "Line Point Intercept",
    "section": "Data Processing",
    "text": "Data Processing\n\nData Entry\nLPI data are recorded in standardized Excel fieldbooks on the same day of data collection, while information and memory are fresh. The ISO3_YEAR_lpi_fieldbook.xlsx is organized as follows:\n\nreadme sheet: Contains expedition info, data entry instructions, and guidelines\nstations sheet: Records station information including sampling depths, survey lengths, and any deviations from protocol.\nobservations sheet: Primary data entry for all LPI point intercepts\n\n\n\nProcessing Pipeline\n\nFile Consolidation\nThe workflow begins by reading all expedition fieldbooks across legs and divers, combining stations and observations into a unified dataset. This includes converting the data from a wide format (best for data entry in the field) to a long data format, best for anaysis and visualiztion. It also include merginbg the work of the benthic and coral divers.\n\n\n\n\n\n\nMerging Benthic and Coral Diver Data\n\n\n\nThis critical step integrates the specialized knowledge of both divers:\n\nBenthic diver identifies functional groups (e.g., “30 points as hard coral”)\nCoral diver provides detailed taxonomic identification of corals\nWe apportion the benthic diver’s points based on the coral diver’s proportional observations\nThis maintains accurate functional group counts while maximizing taxonomic resolution\n\n\n\n\n\nValidation and Cleaning\nStation data is joined with the uvs_sites_fieldbook to validate site information including coordinates, habitat type, and spatial hierarchy. We check depth strata alignment across stations, standardizes formats, and verifies completeness of required fields. Transects are validated to confirm they contain the expected number of points, with exceptions flagged for review.\nAll taxonomic entries undergo validation against master reference lists, with morphotaxa mapped to the appropriate classification hierarchy.\n\n\nBenthic Cover Calculation\nFrom the cleaned data, we calculate percent cover by morphotaxa and functional group for each station. Additional metrics include species richness, diversity indices, and coral health indicators such as bleaching percentages. These station-level calculations are then aggregated to create site averages and region-wide metrics for comparative analysis.\n\n\n\n\n\n\nCore Output Files\n\n\n\nThe pipeline generates four essential files:\n\nlpi_count: raw but clean raw point contacts\nlpi_cover_by_taxa: total points and % cover by morphotaxa and station\nlpi_station_summary: % cover by functional category and station\nlpi_taxa_summary.csv: prevalence across regions, frequency of occurrence, and average cover values\n\n\n\n\n\nDatabase Integration\nFinally, the processed data is formatted for database ingestion with appropriate metadata tags and quality indicators. This standardized approach ensures consistent data structure across expeditions, facilitating long-term monitoring and comparative analysis of marine ecosystems worldwide.\n\n\n\nExploratory Data Analysis\nAfter completion of the data processing pipeline, we employ a separate eda.qmd file to conduct standardized yet flexible exploratory analyses. This approach balances consistency across expeditions with the need for location-specific insights.\nOur EDA workflow includes several core analyses that we produce for every expedition:\nBiodiversity Assessment - Species accumulation curves to evaluate sampling adequacy - Diversity indices (Shannon, Simpson) compared across sites - Species rank-abundance distributions to characterize community structure\nStatistical Comparisons - Tests for significant differences in diversity and cover metrics - Analyses stratified by region, habitat type, and depth - Focus on key functional groups (hard corals, macroalgae, cyanobacteria)\nCommunity Composition - Multivariate analyses of benthic communities (NMDS, cluster analysis) - Visualization of functional group proportions using consistent color palettes - Identification of indicator species for different habitat types\nCoral Health - Bleaching prevalence by species and depth - Disease incidence and severity metrics\nSpatial Visualization - Interactive maps of survey sites with embedded metrics - Geographic pattern analysis",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "index.html#collaborative-framework",
    "href": "index.html#collaborative-framework",
    "title": "Pristine Seas Science Team SOP",
    "section": "Collaborative Framework",
    "text": "Collaborative Framework\nThe Pristine Seas Science Team works across an integrated set of platforms:\n\n\n\n\n\n\n\n GitHub\n\n\n\nVersion control for code, analysis, and documentation\n\n\n\n\n\n\n\n\n Google Drive\n\n\n\nCollaborative document editing and data storage\n\n\n\n\n\n\n\n\n Zotero\n\n\n\nReference management and bibliography\n\n\n\n\n\n\n\n\n\n\n BigQuery\n\n\n\nCentralized database for expedition data\n\n\n\n\n\n\n\n\n Argo NAS\n\n\n\nAt-sea hub for collaborative work\n\n\n\nLearn more about our collaborative tools →"
  },
  {
    "objectID": "field-methods/index.html#expedition",
    "href": "field-methods/index.html#expedition",
    "title": "Overview",
    "section": "Expedition",
    "text": "Expedition\nA complete research campaign to a target geographic area\nExamples: Palau 2023, Maldives 2024\n\nRegion\nLarge-scale geographic area within an expedition zone\nExamples: Northern Islands, Southern Reefs\n\nSubregion\nArea within a region with distinctive environmental characteristics\nExamples: Outer Atolls, Fringing Reef System\n\nLocality\nNamed geographic feature containing multiple sampling sites\nExamples: Helen Reef, Koror Bay\n\nSite\nSpecific location where sampling methods are deployed\nExamples: North Drop-off, East Lagoon\n\n\nStation\nPrecise sampling point where data collection occurs\nExamples: Transect-01, BRUV-Station-05\n\n\nMeasurement/Observation\nIndividual data points collected at a station\nExamples: Fish count, Coral cover percentage",
    "crumbs": [
      "Home",
      "Field Methods",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#integration-for-reef-health-assessment",
    "href": "field-methods/uvs_overview.html#integration-for-reef-health-assessment",
    "title": "Overview",
    "section": "Integration for Reef Health Assessment",
    "text": "Integration for Reef Health Assessment\nThe Pristine Seas methodology integrates data from all survey components to assess ecosystem health through a standardized set of ecological indicators.\n\n\n\n\n\n\n\n\nIndicator\nMetrics\nSignificance\n\n\n\n\nBenthic Composition\n% hard coral and CCA cover\nFoundation of reef structure and growth\n\n\nDegradation Indicators\n% cyanobacteria cover\nEarly warning of environmental stress\n\n\nFish Community\nTotal fish biomass\nOverall ecosystem productivity\n\n\nTrophic Integrity\n% biomass of sharks and top predators\nFood web completeness\n\n\nInvertebrate Status\nDensity of key commercial species\nResource extraction indicator\n\n\nRecovery Potential\nCoral recruitment density\nFuture reef trajectory\n\n\n\n\n\n\n\nThese metrics provide a holistic assessment of marine ecosystem condition, enabling effective conservation planning and monitoring. We are currently developing a composite reef health index that integrates these indicators into a single, standardized measure to better communicate ecosystem status and facilitate comparative analyses.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)"
    ]
  },
  {
    "objectID": "field-methods/uvs_overview.html#integration-for-reef-health-assessment-1",
    "href": "field-methods/uvs_overview.html#integration-for-reef-health-assessment-1",
    "title": "Underwater Visual Surveys",
    "section": "Integration for Reef Health Assessment",
    "text": "Integration for Reef Health Assessment\nThe Pristine Seas methodology integrates data from all survey components to assess ecosystem health through a standardized set of ecological indicators.\n\nKey Metrics Calculated\n\n\n\n\n\n\n\n\nIndicator\nMetrics\nSignificance\n\n\n\n\nBenthic Composition\n% hard coral and CCA cover\nFoundation of reef structure and growth\n\n\nDegradation Indicators\n% cyanobacteria cover\nEarly warning of environmental stress\n\n\nFish Community\nTotal fish biomass\nOverall ecosystem productivity\n\n\nTrophic Integrity\n% biomass of sharks and top predators\nFood web completeness\n\n\nInvertebrate Status\nDensity of key commercial species\nResource extraction indicator\n\n\nRecovery Potential\nCoral recruitment density\nFuture reef trajectory\n\n\n\nThese metrics provide a holistic assessment of marine ecosystem condition, enabling effective conservation planning and monitoring. The co-located design of our surveys ensures valid ecological comparisons across components while maintaining methodological integrity in the field. These metrics provide a holistic assessment of marine ecosystem condition, enabling effective conservation planning and monitoring. The co-located design of our surveys ensures valid ecological comparisons across components while maintaining methodological integrity in the field.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#limitation",
    "href": "field-methods/benthic_lpi.html#limitation",
    "title": "Benthic Line Point Intercept",
    "section": "Limitation",
    "text": "Limitation",
    "crumbs": [
      "Home",
      "Field Methods",
      "Benthic Line Point Intercept"
    ]
  },
  {
    "objectID": "field-methods/benthic_lpi.html#limitations",
    "href": "field-methods/benthic_lpi.html#limitations",
    "title": "Line Point Intercept",
    "section": "Limitations",
    "text": "Limitations\nWhile the Line Point Intercept (LPI) method offers efficiency and standardization for coral reef monitoring, several methodological trade-offs warrant consideration:\n\nPoint spacing\nSome research suggests 20cm intervals may be too close. Studies comparing intervals found 50cm spacing reduces survey time while still detecting major cover trends, though at the cost of potentially missing rarer species (Facon et al., 2016; Kuo et al., 2022). Statistical power analyses indicate substantially larger sample sizes than typically used are needed to detect even moderate changes in cover regardless of spacing (Leujak & Ormond, 2007).\n\n\nTransect length\nThe standard 50m transect represents a compromise between survey effort and habitat representation. Multiple shorter transects often provide better representation of reef spatial heterogeneity than fewer longer ones (Vallès et al., 2019). Linear methods inherently sample only a tiny proportion of reef area compared to quadrat approaches (0.33% vs 17.8% in some studies).\n\n\nAlternative methods\nFor bleaching assessment specifically, quadrat methods have demonstrated advantages in capturing colony-level impacts and detecting more species than point methods (Brown et al., 2015; Coral Reef Alliance, 2024). Belt transects provide a reasonable compromise for characterizing both coral cover and condition. We continue using LPI methods for consistency with historical data while acknowledging these limitations in our analyses and reports.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Line Point Intercept"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#drive-structure",
    "href": "collaborative-infra/drive.html#drive-structure",
    "title": "Google Drive",
    "section": "Drive Structure",
    "text": "Drive Structure\nThe Pristine Seas Google Drive follows a standardized organizational framework to ensure consistency across expeditions and streamline data management workflows. This structured approach facilitates efficient data retrieval, promotes collaboration, and preserves institutional knowledge.\n\nRoot-Level Organization\nThe root level of our Science Team Google Drive contains these primary folders that support different aspects of our research operations:\n\n\n\n expeditions/\n\n\n\n projects/\n\n\n\n datasets/\n\n\n\n presentations/\n\n\n\n education/\n\n\n\n legacy data/",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#folder-structure",
    "href": "collaborative-infra/drive.html#folder-structure",
    "title": "Google Drive",
    "section": "Folder Structure",
    "text": "Folder Structure\nEach expedition folder follows a consistent organization with the following components:\nexpeditions/\n└── iso3_year/\n    ├── readme.md                # Expedition overview\n    ├── data/                    # All expedition data\n    │   ├── primary/             # Data collected by team\n    │   │   ├── raw/             # Unmodified field data\n    │   │   ├── processed/       # QA/QC applied data\n    │   │   └── output/          # Analysis-ready data\n    │   └── secondary/           # Data from external sources\n    ├── documents/               # Administrative documents\n    ├── figures/                 # Maps and visualizations\n    ├── gis/                     # Spatial data\n    ├── media/                   # Photos, videos, audio\n    ├── presentations/           # Slide decks\n    ├── reports/                 # Expedition outputs\n    └── references/              # Literature and resources",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#root-level-organization",
    "href": "collaborative-infra/drive.html#root-level-organization",
    "title": "Google Drive",
    "section": "",
    "text": "The Drive is organized into these primary top-level folders, each serving a specific purpose within our research workflow:\n\n\nThe primary organizational unit and central hub for all expedition-specific work. Each expedition has a dedicated subfolder with a standardized internal structure for data, documents, and outputs.\nNaming convention: [ISO3]_[YEAR] (e.g., PLW_2023, COL_2022)\nPurpose: Contains all materials directly related to field expeditions, from planning through reporting\n\n\n\nHouses focused research initiatives that either relate to specific expeditions or address cross-cutting thematic areas. Projects maintain consistent internal organization while enabling flexibility for diverse research objectives.\nNaming convention: prj-[Focus]-[Description] (e.g., prj-PLW-sixgill, prj-EU-trawl)\nPurpose: Organizes materials for manuscripts, expedition-adjacent analyses, and broader research initiatives\n\n\n\nCollection of reference datasets that support multiple projects and expeditions, including both external resources and derived datasets with broad applicability.\nOrganization: Structured by geographic scope (global, regional) and thematic categories\nPurpose: Provides consistent access to important contextual data that informs multiple research efforts\n\n\n\nRepository of presentation materials, templates, and visual assets used across the team for internal reporting, external communication, and conference participation.\nOrganization: Categorized by purpose (expedition reports, conferences) with a dedicated visual assets section\nPurpose: Maintains institutional knowledge through documentation of past presentations and ensures visual consistency\n\n\n\nResources for educational initiatives and outreach programs that translate Pristine Seas research into accessible formats for diverse audiences.\nOrganization: Structured by target audience and delivery format\nPurpose: Supports the translation of scientific findings into educational materials with broader impact\n\n\n\nHistorical datasets that predate our current standardized system, maintained in their original structure until integration into the BigQuery database.\nOrganization: Preserved in original format with added documentation\nPurpose: Ensures valuable historical data remains accessible while pending standardization and integration",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#naming-conventions",
    "href": "collaborative-infra/drive.html#naming-conventions",
    "title": "Google Drive",
    "section": "Naming Conventions",
    "text": "Naming Conventions\n\n\n\n\n\n\nFile & Folder Naming\n\n\n\n\nFolder names use hyphens: project-name/, field-method/\nFile names use underscores: PLW_2023_expedition_sites.csv\nAlways use lowercase snake_case: expedition_report.pdf\n\nConsistent naming makes files easier to find, sort, and process.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#root-level-organization-1",
    "href": "collaborative-infra/drive.html#root-level-organization-1",
    "title": "Google Drive",
    "section": "Root-Level Organization",
    "text": "Root-Level Organization\nThe Drive is organized into these primary top-level folders, each serving a specific purpose within our research workflow:\n\n expeditions/\nThe primary organizational unit and central hub for all expedition-specific work. Each expedition has a dedicated subfolder with a standardized internal structure for data, documents, and outputs.\nNaming convention: [ISO3]_[YEAR] (e.g., PLW_2023, COL_2022)\nPurpose: Contains all materials directly related to field expeditions, from planning through reporting\n\n\n projects/\nHouses focused research initiatives that either relate to specific expeditions or address cross-cutting thematic areas. Projects maintain consistent internal organization while enabling flexibility for diverse research objectives.\nNaming convention: prj-[Focus]-[Description] (e.g., prj-PLW-sixgill, prj-EU-trawl)\nPurpose: Organizes materials for manuscripts, expedition-adjacent analyses, and broader research initiatives\n\n\n datasets/\nCollection of reference datasets that support multiple projects and expeditions, including both external resources and derived datasets with broad applicability.\nOrganization: Structured by geographic scope (global, regional) and thematic categories\nPurpose: Provides consistent access to important contextual data that informs multiple research efforts\n\n\n presentations/\nRepository of presentation materials, templates, and visual assets used across the team for internal reporting, external communication, and conference participation.\nOrganization: Categorized by purpose (expedition reports, conferences) with a dedicated visual assets section\nPurpose: Maintains institutional knowledge through documentation of past presentations and ensures visual consistency\n\n\n education/\nResources for educational initiatives and outreach programs that translate Pristine Seas research into accessible formats for diverse audiences.\nOrganization: Structured by target audience and delivery format\nPurpose: Supports the translation of scientific findings into educational materials with broader impact\n\n\n legacy_data/\nHistorical datasets that predate our current standardized system, maintained in their original structure until integration into the BigQuery database.\nOrganization: Preserved in original format with added documentation\nPurpose: Ensures valuable historical data remains accessible while pending standardization and integration",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#overview-1",
    "href": "collaborative-infra/drive.html#overview-1",
    "title": "Google Drive",
    "section": "Overview",
    "text": "Overview\nGoogle Drive serves as the primary collaborative hub for the Pristine Seas Science Team, providing centralized storage and organization for all expedition data, documents, presentations, and project materials. As the foundational component of our digital infrastructure, Drive enables seamless collaboration, ensures data accessibility across the team, and maintains the continuity of our scientific work.\nOur Drive implementation serves several critical functions:\n\nCentral Repository: Houses all primary and secondary data, from raw field observations to processed datasets\nDocument Management: Maintains all expedition and project documentation, including plans, permits, reports, and manuscripts\nKnowledge Base: Preserves institutional knowledge through standardized organization of past work\nCollaboration Platform: Facilitates real-time collaborative editing and review processes\nAsset Library: Organizes visual materials, presentations, and reference resources\n\nThis document outlines the standardized structure, naming conventions, and best practices for our Google Drive usage, ensuring consistency across expeditions and maximizing the utility of our shared resources.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#folder-structure-1",
    "href": "collaborative-infra/drive.html#folder-structure-1",
    "title": "Google Drive",
    "section": "Folder Structure",
    "text": "Folder Structure",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#structure-1",
    "href": "collaborative-infra/drive.html#structure-1",
    "title": "Google Drive",
    "section": "Structure",
    "text": "Structure\nThe Pristine Seas Drive has six main folders, each with a specific purpose:\nOur folder structure is designed around our core workflow, separating expedition-specific content from broader projects and reference materials. This organization helps maintain data integrity while enabling efficient cross-project analysis and knowledge sharing.\n📁 expeditions/\n   └── 📁 COL_2022/\n   └── 📁 PLW_2023/\n   └── 📁 MDV_2024/\n\n📁 projects/\n   └── 📁 prj-PLW-sixgill/\n   └── 📁 prj-EU-trawl/\n   └── 📁 prj-global-seamounts/\n\n📁 datasets/\n   └── 📁 global/\n   └── 📁 regional/\n\n📁 presentations/\n   └── 📁 expedition_reports/\n   └── 📁 conference_presentations/\n   └── 📁 visual_assets/\n\n📁 education/\n\n📁 legacy_data/\n:::",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#expeditions",
    "href": "collaborative-infra/drive.html#expeditions",
    "title": "Google Drive",
    "section": "Expeditions",
    "text": "Expeditions\nThe expeditions folder is the heart of our data organization system, containing all materials related to our field expeditions. Expeditions are given standardized ID (exp_id) that’s composed of the ISO alpha-3 country code and the year of the expedition. In rare case when multiple expeditions occur in the same country within the same year, we add descriptive suffixes.\n\n\n\n\n\n\nExpedition ID (exp_id)\n\n\n\nFormat: [iso3]_[year]\nExamples: COL_2022, PLW_2023, ARG_2018_yaganes, ARG_2018_burwood\n\n\nThis naming system ensures expeditions are easily identifiable, correctly sorted by location and date, and consistently referenced across our platforms.\nexpeditions/\n└── iso3-year/\n    ├── readme.md                # Expedition overview\n    ├── data/                    # All expedition data\n    │   ├── primary/             # Data collected by team\n    │   │   ├── raw/             # Unmodified field data\n    │   │   ├── processed/       # QA/QC applied data\n    │   │   └── output/          # Analysis-ready data\n    │   └── secondary/           # Data from external sources\n    ├── documents/               # Scouting and planning documents\n    ├── figures/                 # Maps and visualizations\n    ├── gis/                     # Spatial project\n    ├── media/                   # Photos, videos\n    ├── presentations/           # Slide decks\n    ├── reports/                 # Expedition outputs\n    └── references/              # Literature and resources\n\n\n\n\n\n\nNaming conventions\n\n\n\nAll folder and file names should follow these conventions:\n\nFolders: Use kebab-case (hyphens), capitalize only proper nouns\n\nExamples: esv-PLW-2024/, prj-cyprus-trawlers/\n\nFiles: Use snake_case (underscores), capitalize only proper nouns\n\nExamples: FJI_2025_science_report.docx, YSI_manual.pdf\n\nNames should be descriptive and consistent\n\n\n\n\ndata/\nThe data folder is organized by source and processing stage:\n\nprimary/secondary/\n\n\nData collected by our team during the expedition:\n\nraw/:\n\nOriginal, unmodified fieldbooks\nSite and species photos\nHighlights from remote camera systems\n\nprocessed/:\n\nQA/QC procedures applied\nStandardized formats\n\noutput/:\n\nFully validated datasets\nDatabase-ready structure\nDerived metrics included\n\n\nEach subfolder is organized by research method (benthic, fish, bruvs, edna, etc.)\n\n\nData from external sources relevant to the expedition:\n\nprevious-work/: Previous research\nspatial/: Habitat maps, administrative boundaries\n\n\n\n\n\n\ndocuments/\nEssential expedition documentation:\n\nplanning/\n\nScouting reports and initial assessments\nScience plans detailing research objectives\n\npermits/\n\nResearch authorization applications and approvals\nMemoranda of understanding with local partners\n\nmisc/\n\nMeeting notes from planning and field sessions\nContact lists for team members and stakeholders\n\n\n\n\nmedia/\nExpedition visual documentation organized by source:\n\nscience-collection/\n\nSelect photos taken by science team members\nOrganized by species groups and habitats\n\nmedia-team/\n\nProfessional photography from our media team\nunderwater/: Underwater imagery of marine environments\ntopside: Aerial and landscape documentation\npeople: Human elements including team and communities\n\nfield-edit/\n\nExpedition video produced by the media team\n\n\n\n\nreports/\nExpedition outputs for different audiences:\n\nscience/\n\nComprehensive scientific report\nTwo-page expedition summary\n\noutreach/\n\nCommunity and stakeholder reports\nPress materials\nStories from the expedition\n\nassets/\n\nHigh-resolution images, maps and figures (.pdf)\nPartner logos or branding materials\n\n\n\n\nOther Key Folders\n\nfigures/\n\nMaps showing expedition sites and spatial patterns in data\nData visualizations from analyses\n\nGIS/\n\nStores the GIS project files\n\npresentations/\n\nPre-expedition planning briefings\nPost-expedition event materials\nOther stakeholder and partner presentations\n\nreferences/\n\nRegional scientific literature\nDomain-specific research papers\nCultural and historical context",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#projects",
    "href": "collaborative-infra/drive.html#projects",
    "title": "Google Drive",
    "section": "Projects",
    "text": "Projects\nThe projects folder houses focused research initiatives and scientific papers that advance our mission. These may span global, regional, or expedition-specific contexts. Projects are given unique descriptive names that reflect their focus and objectives.\n\n\n\n\n\n\nProject ID\n\n\n\nEach project uses a standardized folder naming convention:\nFormat: prj-[descriptive]-[name]\nExamples: prj-SLI-resilience, prj-cachalote, prj-hawaii-lwr\n\n\n\nStructure\nA typical project structure contains the following folders:\nprojects/\n└── prj-[descriptive]-[name]/\n    ├── data/              # Project data (may link to but not copy expedition data)\n    ├── documents/         # Reference documents, meeting notes,\n    ├── figures/           # Plots, maps, visualizations\n    └── presentations/     # Project presentations\n\n\n\n\n\n\nGitHub Integration\n\n\n\n\nCode Management Policy\nAll code and scripts must be stored exclusively in GitHub repositories, never in Google Drive.\n\nDrive: Documents, data, media, and presentations\nGitHub: All code, scripts, and computational workflows\n\n\n\nRepository Naming Conventions\n\nExpeditions: exp-[iso3]-[year] (e.g., exp-MDV-2023)\nProjects: prj-[descriptive]-[name] (e.g., prj-cachalote)\n\nThis clear separation ensures proper version control, enables code review, facilitates collaboration, and maintains the integrity of our scientific workflow.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#datasets",
    "href": "collaborative-infra/drive.html#datasets",
    "title": "Google Drive",
    "section": "Datasets",
    "text": "Datasets\nThe datasets folder contains reference data from external sources that supports our analyses and provides essential context for our research. We maintain these datasets in their original form while providing comprehensive documentation.\n\nStructure\ndatasets/\n├── datasets_inventory.xlsx   # Master catalog with metadata and documentation\n├── aquamaps-v10-2019/        # Original dataset as obtained from source\n├── global-distribution-seagrass/\n├── gebco-2024/               # Bathymetry and ocean topography\n└── [dataset-name]/           # Additional reference datasets\n\n\nDataset Documentation\nOur datasets_inventory.xlsx catalogs each dataset with essential metadata:\n\nSource information: Original creator, publication references, access date\nGeographic scope: Spatial coverage, resolution, and coordinate systems\nTemporal range: Time period covered and update frequency\nContent description: Key variables, measurements, and units\nUsage limitations: Licensing, restrictions, and attribution requirements\n\n\n\nKey Reference Datasets\n\nmarine-regions: Standardized marine boundaries and maritime zones\nmpa-atlas: Global marine protected area database\ngravity-cinner-et-al: Market gravity model for human pressure\nhuman-impacts-on-ocean: Cumulative human impact assessments\nmarine-biogeographic-realms: Major biogeographic divisions\nmarine-ecoregions-and-provinces: Ecological classification system\nseamounts-yesson-2019: Global seamount locations and characteristics",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#presentations",
    "href": "collaborative-infra/drive.html#presentations",
    "title": "Google Drive",
    "section": "presentations/",
    "text": "presentations/\nA repository of slide decks from previous presentations, including expedition debriefs, with a subfolder for visual assets (logos, etc.).",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#education",
    "href": "collaborative-infra/drive.html#education",
    "title": "Google Drive",
    "section": "education/",
    "text": "education/\nResources for educational initiatives (in development).",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#legacy_data",
    "href": "collaborative-infra/drive.html#legacy_data",
    "title": "Google Drive",
    "section": "legacy_data/",
    "text": "legacy_data/\nHistorical data pending integration into our database system.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#core-structure",
    "href": "collaborative-infra/drive.html#core-structure",
    "title": "Google Drive",
    "section": "Core Structure",
    "text": "Core Structure\nThe Pristine Seas Science Team Drive is organized into the following main folders:\nSCIENCE/\n├── expeditions/      # Primary repository for expedition data and documentation\n├── projects/         # Research projects and papers in support of our mission\n├── datasets/         # Useful and commoly used external datasets\n├── resources/          # Shared materials and assets\n│   ├── presentations/    # Slides for presentations, conferences, and meetings\n│   ├── media/            # Photos, videos for communications\n│   ├── illustrations/    # Scientific illustrations library\n│   ├── methods/          # Field protocols and standards\n│   ├── education/        # Training and outreach materials\n└── operations/       # Administrative content\n    ├── team/             # Team coordination\n    │   ├── meetings/        # Meeting notes and schedules\n    │   └── planning/        # Strategic documents\n    ├── equipment/        # Inventory and maintenance\n    ├── budgets/          # Financial planning",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#core-structure-1",
    "href": "collaborative-infra/drive.html#core-structure-1",
    "title": "Google Drive",
    "section": "Core Structure",
    "text": "Core Structure\n\n\n\n📂\n\nexpeditions/\n\n\n\nPrimary repository for all expedition-related data and documentation\n\n\n\n\n🔬\n\nprojects/\n\n\n\nCross-expedition research initiatives and collaborative analyses\n\n\n\n\n🗄️\n\ndatasets/\n\n\n\nReference datasets for global and regional analysis\n\n\n\n\n🎯\n\npresentations/\n\n\n\nArchive of presentation materials and visual assets\n\n\n\n\n📚\n\neducation/\n\n\n\nResources for training and outreach activities\n\n\n\n\n🗃️\n\nlegacy-data/\n\n\n\nHistorical data pending integration into standardized structure",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#naming-convention",
    "href": "collaborative-infra/drive.html#naming-convention",
    "title": "Google Drive",
    "section": "Naming Convention",
    "text": "Naming Convention\nEach expedition has a dedicated folder using the standardized naming convention:\n[iso3]_[year]\nWhere: - iso3 is the ISO 3166-1 alpha-3 country code in lowercase (e.g., mdv for Maldives) - year is the four-digit year of the expedition\nFor multi-country or targeted expeditions, additional descriptors may be added:\n[iso3]_[year]_[descriptor]\nExamples: - mdv_2024 (Maldives 2024) - fji_2023_northern (Fiji 2023 - Northern Islands) - plw_2023 (Palau 2023)\n\n\n\n\n\n\nNote\n\n\n\nThis standardized naming ensures that expedition folders sort chronologically within geographic regions and are immediately identifiable in the file system.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#key-components",
    "href": "collaborative-infra/drive.html#key-components",
    "title": "Google Drive",
    "section": "Key Components",
    "text": "Key Components\n\nreadme.md\nThis is the expedition overview document that serves as the landing page for anyone accessing the expedition folder. It contains:\n\nREADME.md Template\nExpedition: [iso3_year] - [Full Expedition Name]\nDates: [Start Date] - [End Date]\nLocation: [Country, Region]\nScience Team: - [Name] - [Role/Institution] - [Name] - [Role/Institution]\nExpedition Objectives: 1. [Primary research objective] 2. [Secondary research objective] 3. [Conservation/outreach objectives]\nMethods Deployed: - [Method 1] - [Brief description] - [Method 2] - [Brief description]\nKey Accomplishments: - [Summary of surveys completed] - [Notable findings or discoveries] - [Conservation outcomes]\nFolder Navigation: - data/ - [Description of key datasets] - documents/ - [Key documents to reference] - etc.\nContact Information: - Science Lead: [Name] - [Email] - Data Manager: [Name] - [Email]\n\n\n\ndata/\nThe data folder contains all scientific data collected during the expedition, organized by source and processing stage:\n\n\nprimary/\nData collected by the Pristine Seas team during the expedition.\nSubfolders:\n\nraw/ - Original, unmodified data files\nprocessed/ - Data that has undergone QA/QC procedures\noutput/ - Analysis-ready datasets for database ingestion\n\nEach of these subfolders is further organized by research method (benthic, fish, bruvs, edna, etc.).\n\n\nsecondary/\nData from external sources relevant to the expedition.\nSubfolders:\n\nenvironmental/ - Climate, oceanographic, or weather data\nhistorical/ - Previous research in the area\nmanagement/ - Protected area boundaries, regulations\n\nThese data provide context and complement the primary data collected by the team.\n\n\n\nData Organization Principles\n\n\nRaw Data\n\nOriginal, unmodified data files exactly as collected in the field\nInclude fieldbooks, photos, and metadata\nStore in original formats, even if non-standard\nNever modify these files; treat as immutable records\n\n\n\nProcessed Data\n\nData that has undergone QA/QC procedures\nStandardized formats with consistent headers\nClear documentation of processing steps\nTraceable link to raw data sources\n\n\n\nOutput Data\n\nFully validated, analysis-ready datasets\nStandardized structure ready for database ingestion\nIncludes derived metrics (e.g., biomass calculations)\n\n\n\n\n\n\nOther Key Folders\n\n\ndocuments/\nAdministrative and reference documents for the expedition.\nSubfolders:\n\nplanning/ - Scouting and science plans\npermits/ - Research permits, MOUs and authorizations\nmisc/ - Others\n\n\n\nfigures/\nVisual representations of expedition data and findings.\nSubfolders:\n\nmaps/ - Location maps and spatial representations\nplots/ - Data visualizations and statistics\n\n\n\ngis/\nSpatial data and GIS project resources.\nSubfolders:\n\nshapefiles/ - Vector data (points, lines, polygons)\nrasters/ - Gridded spatial data\nmetadata/ - Spatial data documentation\n\n\n\nmedia/\nVisual documentation of the expedition.\nSubfolders:\n\nfield-team/ - Photos taken by science team\nngs/ - Professional photography\nfield-edit/ - Video footage\n\n\n\npresentations/\nSlide decks and presentation materials.\nSubfolders:\n\nplanning/ - Pre-expedition briefings\ndebrief/ - Post-expedition summaries\nstakeholder/ - Materials for local partners\n\n\n\nreports/\nOfficial expedition outputs and reports.\nSubfolders: - science/ - Scientific report. - outreach/ - Public-facing summaries - assets/ - High resolution images and figures for reports\n\n\nreferences/\nExpedition-specific literature and resources.\nSubfolders match Zotero library\n\ngeneral/ - General location references\ndeep-sea/ - Relevant dep sea papers\nculture/ - Cultural references",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#implementation-guide",
    "href": "collaborative-infra/drive.html#implementation-guide",
    "title": "Google Drive",
    "section": "Implementation Guide",
    "text": "Implementation Guide\nTo maintain consistent Drive organization:\n\nCreate templates for new expeditions and projects\nTrain team members on file structure and naming conventions\nConduct regular audits to ensure compliance\nDesignate data champions for expeditions and methods\nDocument exceptions when standard structure cannot be followed",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#resources",
    "href": "collaborative-infra/drive.html#resources",
    "title": "Google Drive",
    "section": "Resources",
    "text": "Resources",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#operations",
    "href": "collaborative-infra/drive.html#operations",
    "title": "Google Drive",
    "section": "Operations",
    "text": "Operations",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#sec1",
    "href": "collaborative-infra/drive.html#sec1",
    "title": "Google Drive",
    "section": "Section 1",
    "text": "Section 1\nContent for section 1…\nNext: Section 2",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#sec2",
    "href": "collaborative-infra/drive.html#sec2",
    "title": "Google Drive",
    "section": "Section 2",
    "text": "Section 2\nContent for section 2…\nPrevious: Section 1 | Next: Section 3",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#sec3",
    "href": "collaborative-infra/drive.html#sec3",
    "title": "Google Drive",
    "section": "Section 3",
    "text": "Section 3\nContent for section 3…\nPrevious: Section 2",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/drive.html#github-integration",
    "href": "collaborative-infra/drive.html#github-integration",
    "title": "Google Drive",
    "section": "GitHub Integration",
    "text": "GitHub Integration\n::: {.callout-important appearance=“minimal” title = “GitHub Integration”}\n\nCode Management Policy\nAll code and scripts must be stored exclusively in GitHub repositories, never in Google Drive.\n\nDrive stores documents, data, and non-code assets\nGitHub provides version control, code review, and collaboration\n\n\nRepository Naming Conventions\n\nExpeditions: exp-[iso3]-[year] (e.g., exp-mdv-2024)\nProjects: prj-[descriptive]-[name] (e.g., prj-coral-resilience)\n\nThis separation ensures proper version tracking and reproducibility while maintaining a clean document management system. :::",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Google Drive"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#github-workflow-with-r",
    "href": "collaborative-infra/github.html#github-workflow-with-r",
    "title": "GitHub",
    "section": "GitHub Workflow with R",
    "text": "GitHub Workflow with R\nOur team primarily interacts with GitHub through RStudio, following the principles outlined in Jenny Bryan’s “Happy Git with R” (happygitwithr.com). This approach simplifies version control while maintaining scientific rigor.\n\nBasic Git Workflow in RStudio\n\n\n\n\n\ngraph LR\n    A[Clone Repository] --&gt; B[Make Changes]\n    B --&gt; C[Stage Changes]\n    C --&gt; D[Commit Changes]\n    D --&gt; E[Pull]\n    E --&gt; F[Push]\n    style F fill:#d8f3dc,stroke:#95d5b2\n\n\n\n\n\n\nThe fundamental GitHub workflow for our team involves these key steps:\n\nClone: Create a local copy of the repository\n\nIn RStudio: File → New Project → Version Control → Git\nEnter repository URL: https://github.com/pristine-seas/repository-name.git\n\nMake Changes: Edit scripts, add analyses, or improve documentation\nStage: Select which changes to include in your commit\n\nIn RStudio: Use the Git pane to check boxes next to changed files\n\nCommit: Save your changes with a clear, descriptive message\n\nIn RStudio: Click “Commit” in the Git pane\nWrite a meaningful commit message that describes what you changed and why\n\nPull: Incorporate any changes others have made\n\nIn RStudio: Click “Pull” in the Git pane\nAddress any conflicts if they arise\n\nPush: Share your changes with the team\n\nIn RStudio: Click “Push” in the Git pane",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#getting-started-with-git-and-r",
    "href": "collaborative-infra/github.html#getting-started-with-git-and-r",
    "title": "GitHub",
    "section": "Getting Started with Git and R",
    "text": "Getting Started with Git and R\nNew team members should start with Jenny Bryan’s “Happy Git with R” guide, which is the definitive resource for R users working with Git:\n\n\n\n\n\n\nEssential Resources\n\n\n\n\nHappy Git and GitHub for the useR - Our primary reference\nInternal training sessions (see edu-r-training repository)\nTeam Slack #github-help channel for specific questions\n\n\n\n\nInitial Setup\nComplete these essential steps (detailed in Happy Git with R):\n\nInstall Git: Set up Git on your computer\nConnect Git and GitHub: Configure your username and credentials\nConnect RStudio to Git: Ensure RStudio can find your Git installation\nCache credentials: Set up a credential helper so you don’t need to authenticate repeatedly\n\n\n\nFirst-Time Repository Setup\nFor a new expedition or project:\n\nCreate repository on GitHub (typically done by team lead)\nClone repository in RStudio\nSet up project structure (use our template repository)\nCreate initial .gitignore file (include data directories)\nMake first commit and push",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#organization-structure",
    "href": "collaborative-infra/github.html#organization-structure",
    "title": "GitHub",
    "section": "Organization Structure",
    "text": "Organization Structure\nThe Pristine Seas Science Team maintains a dedicated GitHub organization (pristine-seas) that houses all our code repositories, documentation, and analytical frameworks.\n\nRepository Types\nOur repositories fall into three main categories, each with specific naming conventions and purposes:\n\n\n\n\n\n\nExpedition Repositories\n\n\n\nNaming convention: exp-[ISO3]-[YEAR]\nPurpose: Code associated with an expedition, including data processing pipelines, analysis scripts, and report generation.\nExamples:\n\nexp-PNG-2024 (Papua New Guinea 2024)\nexp-COL-2022 (Colombia 2022)\nexp-GAB-2023 (Gabon 2023)\n\n\n\n\n\n\n\n\n\nProject Repositories\n\n\n\nNaming convention: prj-[Short-name]-[descriptor]\nPurpose: Code for research projects, thematic analyses, scientific papers, and curiosities.\nExamples:\n\nprj-Cyprus-trawling (Trawling impact analysis)\nprj-scandola-algae (Mediterranean algae study)\nprj-global-sharks (Global shark abundance patterns)\n\n\n\n\n\n\n\n\n\nCore Infrastructure Repositories\n\n\n\nNaming convention: Descriptive names\nPurpose: Central tools, packages, and resources.\nExamples:\n\nscience-sop (This Standard Operating Procedures documentation)\nlegacy-db (Legacy database build)\nPristineSeasR (Pristine Seas R package)\npristine-seas.github.io (Science Team website)",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#getting-help",
    "href": "collaborative-infra/github.html#getting-help",
    "title": "GitHub",
    "section": "Getting Help",
    "text": "Getting Help\nTeam members can get GitHub assistance through:\n\nThe #github-help channel in the team Slack\nHappy Git with R’s Troubleshooting chapter\nDirect mentoring from experienced team members",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#quarto-documents-for-reproducible-research",
    "href": "collaborative-infra/github.html#quarto-documents-for-reproducible-research",
    "title": "GitHub",
    "section": "Quarto Documents for Reproducible Research",
    "text": "Quarto Documents for Reproducible Research\nOur workflow heavily leverages Quarto documents (.qmd files) as the foundation for reproducible research. Quarto combines narrative text, code, and visualizations in a single document that serves as both lab notebook and reproducible pipeline.\n\nWhy We Use Quarto\nQuarto documents offer several advantages for scientific workflows:\n\nCode and narrative integration: Seamlessly mix text with executable R code\nReproducibility: Anyone can re-run analyses and get identical results\nSelf-documentation: Methods are explicitly documented alongside the code\nMultiple output formats: Generate HTML, PDF, Word, or presentations from the same source\nVersion control friendly: Text-based format works well with Git\n\n\n\nQuarto in Our Repository Structure\nOur expedition repositories are organized around two main types of Quarto documents:\n\nPipeline documents (pipeline/ folder):\n\nLinear processing workflows from raw data to analysis-ready datasets\nEmphasize data cleaning, validation, and transformation\nEach document focuses on a specific data stream (benthic, fish, etc.)\nFinal output is typically data tables ready for database ingestion\n\nExploratory Data Analysis (EDA) documents (eda/ folder):\n\nScientific analysis of processed data\nFocus on visualization, statistical testing, and interpretation\nOften include publication-quality figures\nCan be method-specific or integrate across multiple methods",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/github.html#embracing-a-reproducibility-mindset",
    "href": "collaborative-infra/github.html#embracing-a-reproducibility-mindset",
    "title": "GitHub",
    "section": "Embracing a Reproducibility Mindset",
    "text": "Embracing a Reproducibility Mindset\nReproducibility is fundamental to scientific integrity and is a core value of the Pristine Seas Science Team. Beyond just technical practices, it requires a specific mindset when approaching our work.\n\nKey Principles\n\nThink of your future self: Write code and documentation as if you’ll need to understand it months from now with no memory of what you did\nThink of your teammates: Assume someone else will need to use and understand your work without having you available to explain it\nDocumentation is not optional: Clear documentation is as important as the code itself\n\nDocument the “why” not just the “how”\nExplain analytical choices and their implications\nNote data quirks and handling decisions\n\nNo magic numbers: Any constant or parameter should be explained and defined at the top of scripts\nEmbrace iteration: Start with messy exploration, but refine toward reproducible pipelines\n\nInitial EDA can be exploratory\nFinal analyses should be structured as reproducible workflows\nImprove code as clarity emerges\n\n\n\n\nPractical Habits\n\nStart each analysis session by pulling the latest code\nCommit frequently with clear messages\nReview your own work before considering it final\nTest with fresh environments to ensure all dependencies are documented\nKeep raw data pristine and document all transformations",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "GitHub"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#database-architecture",
    "href": "collaborative-infra/bigquery.html#database-architecture",
    "title": "BigQuery",
    "section": "Database Architecture",
    "text": "Database Architecture\nThe Pristine Seas Science Database is organized around two major dataset groups that balance flexibility with consistency:\n\nMethod Datasets: Specific to each survey technique (UVS, BRUVS, eDNA, etc.)\nReference Datasets: Shared taxonomic, spatial, and lookup tables providing a unified backbone\n\n\nDatabase Organization\n\n\n\n\n\ngraph LR\n    %% Main project node\n    pristine[\"pristine-seas\"] \n    \n    %% First level - dataset categories\n    reference_group[\"Reference Datasets\"]\n    method_group[\"Method Datasets\"]\n    \n    %% Reference datasets\n    exp[\"expeditions/\"]\n    tax[\"taxonomy/\"]\n    look[\"lookup/\"]\n    \n    %% Method datasets\n    uvs[\"uvs/\"]\n    pbruv[\"pbruv/\"]\n    sbruv[\"sbruv/\"]\n    edna[\"edna/\"]\n    other[\"Other Methods...\"]\n       %% UVS tables\n    sites[\"sites\"]\n    stations[\"stations\"]\n    \n    %% Fish transect tables\n    blt_group[\"Fish Belt Transect Tables\"]\n    blt1[\"blt_stations\"]\n    blt2[\"blt_observations\"]\n    blt3[\"blt_biomass_by_taxa\"]\n    \n    %% LPI tables\n    lpi_group[\"Benthic LPI Tables\"]\n    lpi1[\"lpi_stations\"]\n    lpi2[\"lpi_counts\"]\n    lpi3[\"lpi_cover_by_taxa\"]\n    \n    %% Taxonomy tables\n    fish[\"fish\"]\n    benthos[\"benthos\"]\n    inverts[\"inverts\"]\n    \n    %% Expeditions tables\n    info[\"info\"]\n    exp_sites[\"sites\"]\n    \n    %% Connections\n    pristine --&gt; reference_group\n    pristine --&gt; method_group\n    \n    reference_group --&gt; exp\n    reference_group --&gt; tax\n    reference_group --&gt; look\n    \n    method_group --&gt; uvs\n    method_group --&gt; pbruv\n    method_group --&gt; sbruv\n    method_group --&gt; edna\n    method_group --&gt; other\n    \n    uvs --&gt; sites\n    uvs --&gt; stations\n    uvs --&gt; blt_group\n    uvs --&gt; lpi_group\n    \n    blt_group --&gt; blt1\n    blt_group --&gt; blt2\n    blt_group --&gt; blt3\n    \n    lpi_group --&gt; lpi1\n    lpi_group --&gt; lpi2\n    lpi_group --&gt; lpi3\n    \n    tax --&gt; fish\n    tax --&gt; benthos\n    tax --&gt; inverts\n    \n    exp --&gt; info\n    exp --&gt; exp_sites\n    \n    %% Styling with improved visibility and contrast\n    classDef root fill:#004165,color:#ffffff,stroke:#002e48,stroke-width:2px,rx:8,ry:8\n    classDef group fill:#f8f9fa,color:#000000,stroke:#343a40,stroke-width:1px,stroke-dasharray: 5 5,rx:5,ry:5\n    classDef refDataset fill:#d4edda,color:#000000,stroke:#28a745,stroke-width:2px,rx:8,ry:8\n    classDef methodDataset fill:#cce5ff,color:#000000,stroke:#0d6efd,stroke-width:2px,rx:8,ry:8\n    classDef table fill:#ffffff,color:#000000,stroke:#6c757d,stroke-width:1px,rx:3,ry:3\n    classDef tableGroup fill:#f8f9fa,color:#000000,stroke:#343a40,stroke-width:1px,rx:3,ry:3\n    \n    class pristine root\n    class reference_group,method_group group\n    class exp,tax,look refDataset\n    class uvs,pbruv,sbruv,edna,other methodDataset\n    class sites,stations,info,exp_sites,blt1,blt2,blt3,lpi1,lpi2,lpi3,fish,benthos,inverts table\n    class blt_group,lpi_group tableGroup\n\n\n\n\n\n\nFor the complete database documenation please refer to the Pristine Seas Database Documentation.\n\n\nCommon Dataset Structures\nEach method dataset follows a consistent pattern with tables organized into logical categories that support various analytical needs. This standardized structure enables efficient querying, cross-method integration, and reproducible science.\n\n\n\n\n\n\nStandard Table Types\n\n\n\n\nSite Tables (sites, [method]_sites)\n\nOne row per survey site or deployment\nContains spatial information, geographic coordinates, habitat descriptions, and context\nKey tables:\n\nexpeditions.sites: aggregates all survey sites across methods and expeditions over time\nuvs.sites: all underwater visual survey sites with method specific metadata.\nsub.sites: all sub dive sites with method specific metadata.\n\n\nStation Tables ([method]_stations)\n\nOne row per sampling unit (e.g., depth strata, replicate)\nIncludes spatial and temporal information, survey effort, and method-specific metadata\nInclude aggregated metrics of interest (e.g., fish biomass, % coral cover)\nFunctions as a primary unit for analysis and comparison\nKey tables:\n\nuvs.lpi_stations: all benthic LPI stations, including transect length, depth, habitat type, and summary metrics.\nuvs.blt_stations: all fish belt transect stations, including transect length, depth, habitat type, and summary metrics.\nsub.stations: all submersible survey stations (horizontal transects) done with the sub.\n\n\nObservation Tables ([method]_observations)\n\nContains individual records (e.g., fish counts, benthic points, video annotations)\nStores raw QAQC’d ecological data with validated taxonomic identifications\nKey tables:\n\nuvs.lpi_counts: all benthic LPI counts, including taxonomic identifications (field_name, morphotaxa, accepted_aphia_ID).\nuvs.blt_observations: all fish belt transect observations, including taxonomic identifications and estimated biomass.\n\n\nStation-Taxa Tables ([method]_[metric]_by_[dimension])\n\nAggregated analysis-ready metrics\nPre-calculated to standardize common analytical outputs\nEnables efficient cross-site and cross-method comparisons\nKey tables:\n\nuvs.cover_by_taxa: total point and % cover by morphotaxa and station.\nuvs.biomass_by_taxa: fish abundance and biomass by taxa and station.\npbruvs.Maxn_by_station: Max N and length estimates per taxa per station",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#data-flow-from-field-to-database",
    "href": "collaborative-infra/bigquery.html#data-flow-from-field-to-database",
    "title": "BigQuery",
    "section": "Data Flow: From Field to Database",
    "text": "Data Flow: From Field to Database\nThe integration of expedition data into BigQuery follows a standardized workflow that ensures data quality and consistency:\n\nField to Database Pipeline\n\n\n\n\n\ngraph LR\n    A[Field Collection] --&gt; B[Validation]\n    B --&gt; C[Storage on NAS]\n    C --&gt; D[Backup to Drive]\n    D --&gt; E[GitHub Pipeline]\n    E --&gt; F[QA/QC Checks]\n    F --&gt; G[BigQuery Ingestion]\n    G --&gt; H[Analysis-Ready Data]\n    \n    style A fill:#f8f9fa,stroke:#495057\n    style B fill:#f8f9fa,stroke:#495057\n    style C fill:#f8f9fa,stroke:#495057\n    style D fill:#e3f2fd,stroke:#1976d2\n    style E fill:#e8f5e9,stroke:#2e7d32\n    style F fill:#e8f5e9,stroke:#2e7d32\n    style G fill:#e3f2fd,stroke:#1976d2\n    style H fill:#e3f2fd,stroke:#1976d2\n\n\n\n\n\n\n\nProcess Steps\n\nField Collection: Researchers collect data using standardized methods and record in digital fieldbooks\nInitial Validation: Field-level data checks ensure completeness and basic quality\nNAS Storage: All expedition data is securely stored on the ship’s Network Attached Storage\nGoogle Drive Backup: Post-expedition, data is organized and backed up to Google Drive\nGitHub Pipeline Processing: Each method’s data undergoes standardized processing via code in expedition repositories\nQuality Assurance: Automated and manual checks verify data integrity and ecological plausibility\nDatabase Ingestion: Processed data is ingested into the appropriate BigQuery tables\nAnalysis: Data becomes available for standardized analysis workflows",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#accessing-and-using-the-database",
    "href": "collaborative-infra/bigquery.html#accessing-and-using-the-database",
    "title": "BigQuery",
    "section": "Accessing and Using the Database",
    "text": "Accessing and Using the Database\nThe Pristine Seas Science Database is designed to be accessible through multiple interfaces, with R being our primary analysis environment.\nFor detailed database documentation, schemas, and comprehensive examples, refer to the Pristine Seas Database Documentation.\n\nAccess Management\nAccess to the Pristine Seas Science Database is managed through Google Cloud IAM:\n\nTeam Members: Full read access to all datasets\nCollaborators: Read access to specific datasets relevant to their work\nPartners: Access via shared exports or temporary read credentials\nPublic: Access to published, non-sensitive data via data packages\n\nTo request access, contact the database administrator with your Google account email and purpose.\n\n\nBest Practices\nWhen working with the Pristine Seas Science Database:\n\nMinimize data transfer: Filter data in BigQuery before collecting to R\nUse primary keys: Join tables using established keys (station_id, site_id)\nReproducible queries: Document your queries in Quarto documents\nAnalysis patterns: Build on established workflows in expedition repositories",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#database-maintenance",
    "href": "collaborative-infra/bigquery.html#database-maintenance",
    "title": "BigQuery",
    "section": "Database Maintenance",
    "text": "Database Maintenance\nThe Pristine Seas Science Database is actively maintained to ensure data quality and accessibility:\n\nVersion Control\n\nMajor schema changes are versioned and documented\nLegacy data structures are preserved for backwards compatibility\nChanges are tracked in the pristine-seas/legacy-db repository\n\n\n\nQuality Control\n\nAutomated data validation checks run on ingestion\nTaxonomic and spatial hierarchies are constantly refined\nIssues can be reported via GitHub issues\n\n\n\nFuture Development\nThe database is continuously evolving to meet research needs:\n\nIntegration of climate and environmental layers\nEnhanced spatial analysis capabilities\nImproved performance for complex queries\nDevelopment of more user-friendly access tools\n\nFor detailed documentation on database structure, tables, and fields, please refer to the complete database documentation.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#data-flow-field-to-database-pipeline",
    "href": "collaborative-infra/bigquery.html#data-flow-field-to-database-pipeline",
    "title": "BigQuery",
    "section": "Data Flow: Field to Database Pipeline",
    "text": "Data Flow: Field to Database Pipeline\nThe integration of expedition data into BigQuery follows a standardized workflow that ensures data quality and consistency:\n\n\n\n\n\nflowchart LR\n    subgraph Field[Field]\n        direction TB\n        A[Collection] --&gt; B[Validation]\n        B --&gt; C[Ship Storage]\n    end\n    \n    subgraph Process[Processing]\n        direction TB\n        D[Drive Backup] --&gt; E[Pipeline Processing]\n        E --&gt; F[Quality Control]\n    end\n    \n    subgraph Database[Database]\n        direction TB\n        G[BigQuery Ingestion] --&gt; H[Analysis-Ready Data]\n    end\n    \n    Field --&gt; Process\n    Process --&gt; Database\n    \n    classDef field fill:#004165,color:#ffffff,stroke-width:1px\n    classDef process fill:#8EBDC8,color:#000000,stroke-width:1px\n    classDef db fill:#E63946,color:#ffffff,stroke-width:1px\n    \n    class Field,A,B,C field\n    class Process,D,E,F process\n    class Database,G,H db\n\n\n\n\n\n\n\nProcess Steps\n\nField Collection: Researchers collect and record data using standardized methods and digital fieldbooks\nInitial Validation: Field-level data checks ensure completeness and quality\nNAS Storage: All expedition data is securely stored on the ship’s Network Attached Storage\nGoogle Drive Backup: Post-expedition, data is organized and backed up to Google Drive\nPipeline Processing: Each method’s data undergoes standardized processing via code in expedition repositories\nQuality Assurance: Automated and manual checks verify data integrity\nDatabase Ingestion: Processed data is ingested into the appropriate BigQuery tables\nAnalysis: Data becomes available for standardized analysis workflows",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#access-and-use",
    "href": "collaborative-infra/bigquery.html#access-and-use",
    "title": "BigQuery",
    "section": "Access and Use",
    "text": "Access and Use\nThe Pristine Seas Science Database is designed to be accessible through multiple interfaces.\n\nRstudio\nThe most common way to interact with our BigQuery database is through R, using the familiar tidyverse workflow.\n\nEstablishing a Connection\nSetting up a connection is straightforward:\n\n# Load required packages\nlibrary(DBI)\nlibrary(bigrquery)\nlibrary(tidyverse)\n\n# Create a database connection\nbq_connection &lt;- DBI::dbConnect(bigrquery::bigquery(),\n                      project = \"pristine-seas\",\n                      billing = \"pristine-seas\")\n\nThis code establishes a connection to the entire database, allowing you to explore datasets and tables directly from the Connections pane in RStudio. The first time you run this code, you’ll be prompted to authenticate with your Google account.\n\n\nUsing dplyr Verbs\nThe real power comes from using familiar dplyr verbs directly with BigQuery tables—no SQL knowledge required:\n\ndf &lt;- tbl(bq_connection, \"taxonomy.fish\") |&gt; \n  group_by(family, genus) |&gt; \n  summarize(n_taxa = n_distinct(accepted_aphia_id),\n            .groups = \"drop\") |&gt; \n  arrange(desc(n_taxa)) |&gt; \n  head(30) |&gt; \n  collect()\n  \ndf |&gt; \n  ggplot()+\n  geom_col(aes(x = fct_reorder(family, n_taxa, sum), \n               y = n_taxa, \n               fill = genus), \n           show.legend = T)+\n  theme_minimal()+\n  coord_flip()+\n  labs(x = \"\", y = \"# Distinct Taxa\", fill = \"\",\n       title = \"Number of fish taxa in taxonomy.fish table\",\n       subtitle = \"By family and genus\")+\n  paletteer::scale_fill_paletteer_d(\"ggsci::default_igv\")\n\n\n\n\n\n\n\n\nWhat makes this approach powerful:\n\nBigQuery does the heavy lifting – All filtering, grouping, and summarizing happens in the database\nOnly results are transferred – Data never loads into memory until you call collect()\nFamiliar syntax – The same dplyr verbs you already use with local data frames\nReadable code – Complex queries expressed in clean, maintainable R code\n\n\n\n\nGoogle BigQuery Console\nThe database can also be accessed directly through the Google BigQuery Console:\n\nVisit console.cloud.google.com/bigquery\nNavigate to the pristine-seas project\nUse the query editor to write and execute SQL queries\nExplore tables, schemas, and query history\n\nThe console provides a user-friendly interface for exploring table structures, examining data samples, and running ad-hoc queries without writing code.\n\n\nAccess Management\nAccess to the Pristine Seas Science Database is managed through Google Cloud IAM:\n\nTeam Members: Full read access to all datasets\nCollaborators: Read access to specific datasets relevant to their work\nPartners: Access via shared exports or temporary read credentials\nPublic: Access to published, non-sensitive data via data packages (still TBD)\n\nTo request access, contact the database administrator with your Google account email and purpose.\n\n\nBest Practices\nWhen working with the Pristine Seas Science Database:\n\nMinimize data transfer: Filter data in BigQuery before collecting to R\nUse primary keys: Join tables using established keys (ps_station_id, ps_site_id)\nReproducible queries: Document your queries in Quarto documents\nAnalysis patterns: Build on established workflows in expedition repositories",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/bigquery.html#maintenance",
    "href": "collaborative-infra/bigquery.html#maintenance",
    "title": "BigQuery",
    "section": "Maintenance",
    "text": "Maintenance\nThe Pristine Seas Science Database is actively being developed and continously improved to meet the needs of our team.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "BigQuery"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#library-structure",
    "href": "collaborative-infra/zotero.html#library-structure",
    "title": "Zotero",
    "section": "Library Structure",
    "text": "Library Structure\nOur Zotero library follows a hierarchical organization that balances expedition-specific needs with thematic categorization:\n\nBooks: Complete reference texts relevant to marine science and conservation\nEconomic Reports: Economic analyses and valuation studies of marine ecosystems\nExpedition References: Literature specific to expedition locations (organized by expedition ID)\n\nOne folder per expedition ID\nThematic subfolders within each expedition (fisheries, benthic communities, regional context)\n\nExpedition Reports: Archive of Pristine Seas expedition reports\nProjects: References for research projects\n\nUses consistent naming conventions that mirror Google Drive and GitHub structures\n\nPS Publications: Pristine Seas scientific publications organized by year\nGeneral References: Thematic collections of literature organized by scientific domain\n\nFisheries\nMPAs\nMesophotic reefs\nOther thematic categories",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#workflow-integration",
    "href": "collaborative-infra/zotero.html#workflow-integration",
    "title": "Zotero",
    "section": "Workflow Integration",
    "text": "Workflow Integration\n\nPre-Expedition\n\nScience lead establishes a new collection for the expedition using the standard expedition ID\nTeam contributes foundational literature about the expedition region including reports and documents from partners.\nScience lead exports and downloads key papers to Google Drive for sharing with external collaborators and the wider Pristine Seas team\nKey papers are flagged for required reading by expedition scientists\n\n\n\nDuring Expedition\n\nLibrary from Google Drive is loaded into the ship’s NAS for redundancy.\nReference materials support species identification and ecological interpretation\nZotero library remains accessible via laptops or tablets\n\n\n\nPost-Expedition Analysis and Reporting\n\nStandardized citation of references in reports and publications\nExport of formatted bibliographies for scientific reports\nAddition of new Pristine Seas publications to the library",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero"
    ]
  },
  {
    "objectID": "collaborative-infra/zotero.html#best-practices",
    "href": "collaborative-infra/zotero.html#best-practices",
    "title": "Zotero",
    "section": "Best Practices",
    "text": "Best Practices\n\nOrganization\n\nFollow standardized naming conventions for collections\nEnsure all references include complete citation information\nAttach PDF files of publications when available\nConduct annual review and cleanup of library organization\n\n\n\nCitation Management\n\nUse of the APA 7th Edition citation style for consistency across all publications\nUtilization of the Google Docs Zotero plugin for collaborative manuscript writing\nDirect citation insertion in Quarto documents via Zotero integration with RStudio",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Zotero"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html",
    "href": "collaborative-infra/argo_NAS.html",
    "title": "Argo NAS",
    "section": "",
    "text": "The Argo Network Attached Storage (NAS) serves as our primary data hub while at sea, providing high-capacity, RAID-configured local storage and file-sharing capabilities independent of internet connectivity. This system enables real-time collaboration, automated data backup, and efficient information exchange among all expedition members.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#overview",
    "href": "collaborative-infra/argo_NAS.html#overview",
    "title": "Argo NAS",
    "section": "",
    "text": "The Argo Network Attached Storage (NAS) serves as our primary data hub while at sea, providing high-capacity, RAID-configured local storage and file-sharing capabilities independent of internet connectivity. This system enables real-time collaboration, automated data backup, and efficient information exchange among all expedition members.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#system-architecture",
    "href": "collaborative-infra/argo_NAS.html#system-architecture",
    "title": "Argo NAS",
    "section": "System Architecture",
    "text": "System Architecture\nThe Argo NAS operates on a dedicated internal network accessible throughout the vessel, offering high-speed data transfer, automated synchronization, and robust storage redundancy. Each expedition member receives personalized access credentials with role-specific permission levels, ensuring appropriate access to data and collaboration spaces.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#directory-structure",
    "href": "collaborative-infra/argo_NAS.html#directory-structure",
    "title": "Argo NAS",
    "section": "Directory Structure",
    "text": "Directory Structure\nFolders on the NAS mirror the structure of the matching expedition folder in Google Drive, ensuring a seamless transition between at-sea operations and post-expedition data management.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#daily-workflow",
    "href": "collaborative-infra/argo_NAS.html#daily-workflow",
    "title": "Argo NAS",
    "section": "Daily Workflow",
    "text": "Daily Workflow\nThe NAS plays a central role in our daily expedition operations:\n\nData entry: Upload collected data and photos to the appropriate directories on the NAS (excluding remote camera footage)\nDaily backup: Automatic daily backup of all new uploads to ensure redundancy and data integrity\nEarly QAQC: Preliminary quality assurance and quality control (QA/QC) conducted by the data manager\nSpecies ID: Collaborative species identification and validation based on shared images and video\nPlanning: Preparation for the following day’s operations based on real-time sampling distribution updates\nHighlights: Sharing of daily highlights, including images, video clips, and key findings.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#best-practices",
    "href": "collaborative-infra/argo_NAS.html#best-practices",
    "title": "Argo NAS",
    "section": "Best Practices",
    "text": "Best Practices\n\nFile Management\n\nFollow standard naming conventions for all folder and files:\n\nExample: benthos/site-photos/PLW-2023-uvs-001/..., sbruv/PLW_2023_sbruv_fieldbook.xlsx\n\nSave work to the NAS daily rather than keeping it on personal devices\nOrganize raw photos by station_id or date upon upload\n\n\n\nCollaborative Etiquette\n\nSave Frequently\nClose files when not in use to prevent access conflicts.\nShare your photos—contribute regularly to foster team collaboration",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#support",
    "href": "collaborative-infra/argo_NAS.html#support",
    "title": "Argo NAS",
    "section": "Support",
    "text": "Support\nThe expedition’s data manager serves as the primary support contact for NAS-related issues, including troubleshooting, folder management, and QA/QC oversight.",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "collaborative-infra/argo_NAS.html#post-expedition-data-management",
    "href": "collaborative-infra/argo_NAS.html#post-expedition-data-management",
    "title": "Argo NAS",
    "section": "Post-Expedition Data Management",
    "text": "Post-Expedition Data Management\nAt the conclusion of each expedition:\n\nAll data undergoes final validation and organization\nComplete dataset is backed up to portable drives\nThe full dataset (excluding raw footage) is synced to Google Drive.\nData is archived for future reference",
    "crumbs": [
      "Home",
      "Collaborative Infrastructure",
      "Argo NAS"
    ]
  },
  {
    "objectID": "field-methods/benthic_overview.html#method-overview",
    "href": "field-methods/benthic_overview.html#method-overview",
    "title": "Overview",
    "section": "Method Overview",
    "text": "Method Overview",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Overview"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#method-overview",
    "href": "field-methods/benthic_inverts.html#method-overview",
    "title": "Invertebrates",
    "section": "Method Overview",
    "text": "Method Overview\nThe invertebrate survey method employs a belt transect approach to systematically document conspicuous mobile invertebrates within a defined search area. This standardized approach enables quantitative comparison of invertebrate communities across sites, regions, and time periods.\n\nKey Features\n\nDefined search area: 50 m × 1 m belt transect (50 m²)\nFocus taxa: Echinoderms, mollusks, crustaceans, and other conspicuous invertebrates\nSize measurements: Targeted measurements of commercially important or ecologically significant species\nStandardized effort: Consistent search time and methodology across all stations\nIntegration: Uses the same transect line deployed for LPI and coral recruit surveys",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#method-overview",
    "href": "field-methods/benthic_recruits.html#method-overview",
    "title": "Recruits",
    "section": "Method Overview",
    "text": "Method Overview",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html",
    "href": "field-methods/benthic_inverts.html",
    "title": "Invertebrates",
    "section": "",
    "text": "Mobile invertebrates are key components of marine ecosystems, serving as both ecological indicators and fulfilling critical functional roles in reef maintenance, herbivory, and nutrient cycling. The Pristine Seas invertebrate survey methodology provides standardized protocols for quantifying the abundance, diversity, and size distribution of conspicuous mobile invertebrates across different habitats and depths. These surveys complement our benthic composition data (LPI) by documenting the mobile fauna that drive essential reef processes and often serve as valuable fishery resources.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#introduction",
    "href": "field-methods/benthic_inverts.html#introduction",
    "title": "Invertebrates",
    "section": "",
    "text": "Mobile invertebrates are key components of marine ecosystems, serving as both ecological indicators and fulfilling critical functional roles in reef maintenance, herbivory, and nutrient cycling. The Pristine Seas invertebrate survey methodology provides standardized protocols for quantifying the abundance, diversity, and size distribution of conspicuous mobile invertebrates across different habitats and depths. These surveys complement our benthic composition data (LPI) by documenting the mobile fauna that drive essential reef processes and often serve as valuable fishery resources.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#overview",
    "href": "field-methods/benthic_inverts.html#overview",
    "title": "Invertebrates",
    "section": "Overview",
    "text": "Overview\nThe invertebrate survey method involves systematically searching a defined belt transect area to identify, count, and measure key mobile invertebrate species. This approach provides quantitative data on invertebrate density, biomass, and community composition, enabling rigorous spatial and temporal comparisons.\n\nKey Features\n\nDefined search area: 50 m × 1 m belt transect (50 m²)\nTaxonomic focus: Conspicuous echinoderms, mollusks, crustaceans, and other mobile invertebrates\nSize estimation: Measurements of key species (e.g., giant clams, trochus snails)\nStandardized effort: Consistent search time and methods across stations\nIntegration: Same transect line as LPI and recruitment surveys",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#field-implementation",
    "href": "field-methods/benthic_inverts.html#field-implementation",
    "title": "Invertebrates",
    "section": "Field Implementation",
    "text": "Field Implementation\n\nCoordination with Other Methods\nThe invertebrate survey is conducted by the same diver who performs the coral recruit survey, as part of the three-person benthic survey team. This specialized diver completes both surveys during a single dive, performing the coral recruit survey first, followed by the invertebrate survey along the same transect line.\n\n\n\n\n\n\nInvertebrate Survey Specifications\n\n\n\n\nTransect dimensions: 50 m × 1 m (50 m²)\nSearch width: 1 m along one side of the transect line\nDirection: From end (50 m) to start (0 m) of the transect\nTiming: Conducted after completing coral recruit quadrats\nDuration: 15-20 minutes per transect (standardized effort)\n\n\n\n\n\nData Collection Procedure\n\nSurvey execution:\n\nAfter completing the coral recruit quadrats, return to the end of the transect\nBegin at the 50 m mark and work toward the 0 m mark\nSystematically search 1 m along one side of the transect line\nMaintain a consistent search speed to standardize effort\n\nData recording:\n\nIdentify all motile invertebrates to species level and count them\nFor culturally and fishery important species, measure sizes in centimeters using slate\nExclude species permanently attached to the seabed (except for scallops, pearl oysters, and giant clams)\nNote unusual behavior or interesting ecological interactions\n\nPhoto documentation:\n\nPhotograph all invertebrates not identified in-situ to species\nCapture additional images of unusual specimens or notable aggregations\nDocument evidence of harvesting or ecological interactions\n\nQuality control notes:\n\nNote any deviations from standard protocol\nDocument search time and any interruptions",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#target-taxa",
    "href": "field-methods/benthic_inverts.html#target-taxa",
    "title": "Invertebrates",
    "section": "Target Taxa",
    "text": "Target Taxa\nThe invertebrate survey counts all motile invertebrates, with special attention to ecologically important and commercially valuable species. While we aim for complete enumeration, these key groups receive priority focus:\n\nMajor Taxonomic Groups\n\n\n\nEchinoderms\n\n\nSea stars (Acanthaster, Linckia)\n\n\nSea urchins (Diadema, Tripneustes)\n\n\nSea cucumbers (all commercial species)\n\n\nFeather stars (crinoids)\n\n\n\n\n\nMollusks\n\n\nGiant clams (Tridacnidae)\n\n\nPearl oysters (including Penguin’s wing)\n\n\nGastropods (Trochus, Triton, Conch)\n\n\nNudibranchs & Cephalopods\n\n\n\n\n\nCrustaceans\n\n\nLobsters (Panulirus, Scyllarides)\n\n\nLarge crabs (Carpilius, Etisus)\n\n\nOther large crustaceans\n\n\n\n\n\n\n\nPriority Species for Measurement\nUsing the centimeter-marked edge of the dive slate, measure sizes of these key species:\n\n\n\n\n\n\n\n\nTaxonomic Group\nSpecies to Measure\nMeasurement\n\n\n\n\nGiant clams\nAll Tridacnidae\nMaximum shell length\n\n\nPearl oysters\nIncluding Penguin’s wing\nShell height\n\n\nGastropods\nTrochus, Triton, Conch, Turban, Green snails\nShell width/length per SPC guide\n\n\nSea cucumbers\nAll commercial species\nBody length when relaxed\n\n\nSea urchins\nNon-boring species (e.g., Tripneustes)\nTest diameter without spines\n\n\nLobsters\nAll species\nCarapace length\n\n\n\nRefer to the SPC invertebrate measurement guide for specific measurement techniques. Additional species may be included based on regional priorities.\n\n\nSpecial Considerations for Key Species\n\nCrown-of-Thorns Starfish (COTS)\nFor each Acanthaster individual, record:\n\nDiameter (cm) from arm tip to opposite arm tip\nActivity: (F) feeding, (M) moving, or (R) resting\nSubstrate and coral association\nAggregation density and condition\n\n\n\nGiant Clams\nFor all Tridacnidae, document:\n\nSpecies-level identification\nMaximum shell length\nPosition: (E) embedded, (L) loose, or (P) partially embedded\nBleaching status or damage\n\n\n\nCommercially Important Species\nFor locally harvested species, note:\n\nSize measurements for population structure assessment\nHabitat associations\nEvidence of harvesting activity\nJuvenile presence",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#special-considerations",
    "href": "field-methods/benthic_inverts.html#special-considerations",
    "title": "Invertebrates",
    "section": "Special Considerations",
    "text": "Special Considerations\n\nCrown-of-Thorns Starfish\nIn regions where Acanthaster outbreaks are a concern, additional data may be collected, including:\n\nSize (diameter) of each individual\nFeeding activity (active feeding, moving, or stationary)\nCondition (healthy, injured, or diseased)\nAggregation characteristics (isolated or clustered)\n\n\n\nGiant Clams\nFor all Tridacnidae encountered:\n\nRecord species-level identification\nMeasure maximum shell length (cm)\nNote substrate type and position (embedded, loose, etc.)\nDocument any signs of harvesting or damage\n\n\n\nCommercially Valuable Species\nFor species targeted by local fisheries:\n\nRecord precise size measurements\nDocument evidence of harvesting pressure\nNote habitat associations and aggregation behaviors",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#taxonomic-resolution",
    "href": "field-methods/benthic_inverts.html#taxonomic-resolution",
    "title": "Invertebrates",
    "section": "Taxonomic Resolution",
    "text": "Taxonomic Resolution\nAll motile invertebrates are identified to species level whenever possible. For specimens that cannot be immediately identified in the field, photographs are taken for later identification using available resources.\n\nIdentification Resources\nThe following resources are available to support species identification:\n\nOn-ship reference books: Expedition vessels are equipped with invertebrate field guides and taxonomic references\nOnline resources:\n\nInvertEBase\nKwajalin Underwater\nSea Slug Forum\nSea Slugs of Hawaii\nFlorent’s Guide\nMyReefGuide\nMarineLifePhotography\n\n\nWhen species-level identification is not possible, the invertebrate survey follows the same taxonomic resolution approach used across all Pristine Seas benthic methods:\n\nField names: Descriptive terms based on obvious morphological characteristics\n\nExamples: “black sea cucumber with red papillae,” “blue-spotted sea star”\n\nMorphotaxa: Consolidation of field names into taxonomic units with distinguishing features\n\nExamples: “Linckia sp. blue,” “Holothuria sp. black with red”\n\nLowest defensible taxonomic rank: Formal taxonomic assignment based on available evidence\n\nExamples: “Linckia laevigata,” “Holothuria atra”\n\nFunctional group: Classification into ecological functional roles\n\nExamples: “Grazing echinoid,” “Deposit-feeding holothuroid”",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#data-processing",
    "href": "field-methods/benthic_inverts.html#data-processing",
    "title": "Invertebrates",
    "section": "Data Processing",
    "text": "Data Processing\n\nData Entry and Management\nInvertenbrates data are recorded in standardized Excel fieldbooks on the same day of data collection, while information and memory are fresh. The ISO3_YEAR_inverts_fieldbook.xlsx is organized as follows:\n\nreadme sheet: Contains expedition info, data entry instructions, and guidelines\nstations sheet: Records station information including sampling depths, habitat types, and protocol details\nobservations sheet: Primary data entry for all invertebrate observations, including counts and measurements\n\n\n\nProcessing Pipeline\nThe data processing workflow follows these key steps:\n\n1. File Consolidation\n\nMerge data across expedition legs and divers\nStandardize taxonomic entries and size measurements\nIntegrate with site metadata from the UVS Sites Fieldbook\nVerify data completeness across all stations\n\n\n\n2. Data Validation and Quality Control\n\nFlag missing data or outliers for review\nCross-check taxonomic entries\nVerify transect lengths and search times\n\n\n\n3. Standardization and Calculation\n\nCalculate density metrics (individuals/m²) for each taxon\nCompute biomass estimates for key species (where length-weight relationships exist)\nGenerate summary statistics by taxonomic group, site, and region\n\n\n\n4. Database Integration\n\nFormat processed data for BigQuery ingestion\nEnsure consistency with other UVS components\n\n\n\n\nCore Output Files\nThe pipeline generates several essential files:\n\ninverts_observations.csv: Cleaned observations with standardized taxonomy\ninverts_density_by_taxa.csv: Density calculations by taxa and station\ninverts_stations.csv: Aggregate metrics by station (richness, total density, key taxa densities)\ninverts_taxa_summary.csv: Regional occurrence patterns and average densities by taxa",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#exploratory-data-analysis",
    "href": "field-methods/benthic_inverts.html#exploratory-data-analysis",
    "title": "Invertebrates",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nOur standard invertebrate data analysis includes several core components that are usually applied across expeditions:\n\nCommunity Composition\n\nTaxonomic richness and diversity indices\nMultivariate analyses (NMDS, cluster analysis)\nFunctional group proportions\n\n\n\nStatistical Analyses\n\nTests for significant differences by region, habitat, and depth\nAnalysis of key indicator species abundance patterns\nCorrelation with benthic cover metrics from LPI\n\n\n\nSpatial Visualization\n\nDensity maps for key taxa\nGeographic distribution patterns\n\n\n\nSize Structure\n\nSize frequency distributions for key species\nComparative size analysis across protection levels\n\n\n\nIntegration with other methods\nThe invertebrate survey data can be analyzed alongside other Pristine Seas survey methods:\n\nWith LPI data: Examining relationships between benthic composition and invertebrate communities\nWith fish data: Investigating predator-prey relationships and trophic cascades\nWith coral recruit data: Assessing potential impacts of invertebrate grazers on coral recruitment\nWith eDNA data: Comparing visual detection with molecular detection of invertebrate diversity",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#limitations",
    "href": "field-methods/benthic_inverts.html#limitations",
    "title": "Invertebrates",
    "section": "Limitations",
    "text": "Limitations\nWhile the belt transect methodology is effective for surveying many mobile invertebrates, several limitations should be considered:\n\nHabitat complexity: Detection probability varies with substrate complexity\nCryptic behavior: Many invertebrates are hidden within complex reef structures\nNocturnal activity: Daytime surveys miss species active primarily at night\nDiver avoidance: Some mobile species actively avoid divers\nSpatial clumping: Patchy distribution may result in high variance between transects",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html",
    "href": "field-methods/benthic_recruits.html",
    "title": "Coral Recruits",
    "section": "",
    "text": "Coral recruitment is a fundamental process driving reef recovery, resilience, and long-term persistence. The Pristine Seas coral recruit survey methodology provides standardized protocols for quantifying juvenile coral abundance, taxonomic composition, and size distribution across different habitats and depths.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#introduction",
    "href": "field-methods/benthic_recruits.html#introduction",
    "title": "Coral Recruits",
    "section": "",
    "text": "Coral recruitment is a fundamental process driving reef recovery, resilience, and long-term persistence. The Pristine Seas coral recruit survey methodology provides standardized protocols for quantifying juvenile coral abundance, taxonomic composition, and size distribution across different habitats and depths.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#overview",
    "href": "field-methods/benthic_recruits.html#overview",
    "title": "Coral Recruits",
    "section": "Overview",
    "text": "Overview\nThe coral recruit survey protocol involves systematically examining fixed-area quadrats along a transect to identify and measure juvenile coral colonies. This approach provides quantitative data on recruitment density, taxonomic patterns, and early post-settlement survival, enabling assessments of reef recovery potential.\n\nKey Features\n\nStandardized quadrats: Fixed-area sampling units (50 × 50 cm)\nSystematic placement: Regular intervals along the LPI transect\nSize-based approach: Focus on colonies ≤5 cm maximum diameter\nTaxonomic resolution: Identification to genus or species level when possible\nPhotographic documentation: Each quadrat is photographed before examination\nIntegration: Same transect line used for LPI and invertebrate surveys",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#field-implementation",
    "href": "field-methods/benthic_recruits.html#field-implementation",
    "title": "Coral Recruits",
    "section": "Field Implementation",
    "text": "Field Implementation\nThe recruit survey is typically conducted by the recruit/invert diver as part of the three-person benthic survey team. This specialized diver completes both the coral recruit and invertebrate surveys during a single dive, performing these tasks in sequence.\n\n\n\n\n\n\nCoral Recruit Survey Specifications\n\n\n\n\nQuadrat dimensions: 50 × 50 cm (0.25 m²)\nQuadrat placement: Every 5 m along the transect (10 quadrats total)\nPlacement positions: 0, 5, 10, 15, 20, 25, 30, 35, 40, and 45 m marks\nTiming: Conducted before invertebrate surveys\nTarget size range: Corals ≤5 cm maximum diameter\n\n\n\n\nData Collection Procedure\n\nDeployment coordination:\n\nThe recruit survey utilizes the same 50 m transect line deployed for the LPI survey\nBegin at the 0 m mark and proceed along the transect\n\nQuadrat placement:\n\nPlace the quadrat on the substrate at each 5 m interval along the transect (0, 5, 10, …, 40, and 45 m marks)\nThe combined survey area across all quadrats is 2.5 m² per transect\n\nQuadrat documentation:\n\nBefore searching for juveniles, take a photograph looking down into each quadrat\n\nQuadrat examination:\n\nSystematically search the entire quadrat area\nFocus on colonies ≤5 cm maximum diameter that have a distinct tissue and skeletal boundary\nExclude fragments or remnants of larger colonies\n\nData recording:\n\nFor each juvenile coral within the quadrat:\n\nIdentify to lowest possible taxonomic level (genus or species)\nMeasure maximum diameter to the nearest 0.5 mm (for colonies larger than 0.5 cm)\nNote the quadrat number to link records back to the quadrat image\nDocument attachment substrate type\nNote any partial mortality, bleaching, or disease\n\nRecord quadrat-level information:\n\nDominant substrate type\nApproximate sediment cover (%)\n\n\nPhoto documentation:\n\nPhotograph unidentified or unusual recruits for later verification\nTake reference images of representative recruits\nCapture full quadrat images\n\nCompletion and transition:\n\nAfter examining all 10 quadrats, stow equipment securely\nTransition to invertebrate surveys (working back along the same transect)",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#taxonomic-resolution",
    "href": "field-methods/benthic_recruits.html#taxonomic-resolution",
    "title": "Coral Recruits",
    "section": "Taxonomic Resolution",
    "text": "Taxonomic Resolution\nJuvenile corals are often difficult to identify to species level due to their small size and undeveloped morphological features. Given these constraints, our survey employs a pragmatic approach to taxonomic resolution.\n\nGenus-level identification for most recruits\nSpecies-level identification when morphological features are sufficiently developed\nFamily-level grouping for the smallest recruits (≤1 cm)\nPhotographic documentation for verification and training purposes",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#substrate-classification",
    "href": "field-methods/benthic_recruits.html#substrate-classification",
    "title": "Coral Recruits",
    "section": "Substrate Classification",
    "text": "Substrate Classification\nThe substrate to which coral recruits are attached is recorded using these categories:\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae\n\n\n\nMacroalgae Base Attached to base of macroalgal holdfasts\n\n\n\nBare Substrate Directly attached to exposed rock or pavement\n\n\n\nCoral Rubble Attached to fragments of dead coral\n\n\n\nDead Coral (intact) Attached to intact dead coral structure\n\n\n\nOther Attached to other organisms or substrates",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#data-processing",
    "href": "field-methods/benthic_recruits.html#data-processing",
    "title": "Coral Recruits",
    "section": "Data Processing",
    "text": "Data Processing\n\nData Entry\nCoral recruit data are recorded in standardized Excel fieldbooks on the same day of data collection, while information and memory are fresh. The ISO3_YEAR_recruits_fieldbook.xlsx is organized as follows:\n\nreadme sheet: Contains expedition info, data entry instructions, and guidelines\nstations sheet: Records station information including sampling depths, habitat types, and any deviations from protocol\nrecruits sheet: Primary data entry for all coral recruits, including , size measurements and substrate type, and quadrat level info\n\n\n\n\n\n\n\nQuadrat Image Organization\n\n\n\nThe systematic organization of quadrat images is essential for later reference and quality control\n\nAll images should be named following the convention: [exp_id][site][depth]_[quadrat#].jpg\nImages should be stored in a folder structure mirroring the site&gt;station hierarchy\n\n\n\n\n\nProcessing Pipeline\nThe data processing workflow follows these key steps:\n\nFile Consolidation:\n\nMerge data across expedition legs and divers\nStandardize taxonomic names\nIntegrate with site metadata from the UVS Sites Fieldbook\n\nData Validation:\n\nVerify completeness of required fields\nFlag outliers for size measurements\nCross-reference taxonomic entries against adult coral taxa observed in LPI\nEnsure consistent species identifications across observers\n\nDensity Calculation:\n\nCalculate recruit density per unit area (recruits/m²)\nGenerate summary statistics by taxa, size class, site, and region\nCreate standardized density metrics for comparisons\n\nSize Structure Analysis:\n\nGroup recruits into standardized size classes\nAnalyze size frequency distributions by taxa and site\nCalculate size-based demographic metrics\n\nDatabase Integration:\n\nFormat processed data for database ingestion\nApply appropriate metadata tags and quality indicators\nEnsure consistency with other UVS components\n\n\n\n\nCore Output Files\nThe pipeline generates several essential files:\n\nrecruits_observations.csv: Cleaned observations with standardized taxonomy\nrecruits_density_by_taxa.csv: Density calculations by taxa, size class, and station\nrecruits_station_summary.csv: Aggregate metrics by station\nrecruits_taxa_summary.csv: Occurrence and density by taxa across regions",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#exploratory-data-analysis",
    "href": "field-methods/benthic_recruits.html#exploratory-data-analysis",
    "title": "Coral Recruits",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nStandard analyses conducted for coral recruit data include:\n\nRecruitment Patterns:\n\nTaxonomic composition of recruits across sites\nRecruitment density comparisons by region, habitat, and depth\nCorrelation with adult coral cover from LPI\n\nSize Structure:\n\nSize frequency distributions by taxa\nProportional representation across size classes\n\nSubstrate Preferences:\n\nSettlement substrate analysis by taxa\nRelationship between substrate availability and recruitment\n\nSpatial Visualization:\n\nGeographic pattern analysis\nIntegration with environmental variables",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#limitations",
    "href": "field-methods/benthic_recruits.html#limitations",
    "title": "Coral Recruits",
    "section": "Limitations",
    "text": "Limitations\nThe quadrat methodology for coral recruit surveys has several inherent limitations:\n\nDetection challenges: The smallest recruits (&lt;5 mm) are extremely difficult to detect in field conditions, potentially leading to underestimates of recent recruitment\nTaxonomic uncertainty: Accurate species-level identification of recruits is challenging and often not possible for the smallest size classes\nSpatial heterogeneity: Recruitment can be highly patchy, requiring sufficient sample sizes to characterize site-level patterns\nTemporal variability: Recruitment is often episodic, with significant seasonal and annual variations that may not be captured in single surveys\nPost-settlement mortality: High mortality rates in the first weeks after settlement mean that visible recruits represent only a small fraction of initial settlers\n\nThese limitations can be addressed through:\n\nComprehensive diver training in recruit detection and identification\nAdequate sample sizes (minimum of 10 quadrats per depth)\nIntegration with longer-term monitoring where applicable\nSize-based classification to distinguish cohorts",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#special-considerations",
    "href": "field-methods/benthic_recruits.html#special-considerations",
    "title": "Coral Recruits",
    "section": "Special Considerations",
    "text": "Special Considerations\n\nMorphological Plasticity\nJuvenile corals often display different morphologies than adult colonies of the same species, requiring specialized identification skills. Characteristics used for adult coral identification may not be apparent in recruits, necessitating a focus on skeletal structures and early growth patterns.\n\n\nEcological Significance\nWhile coral recruitment is essential for reef recovery, it does not guarantee successful reef replenishment. The survival and growth of recruits into reproductively active adult colonies depend on multiple factors including:\n\nHerbivore abundance (algal control)\nPredation pressure\nEnvironmental conditions\nFrequency of disturbance events\n\nTherefore, recruitment data should be interpreted alongside other ecological indicators.",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#references",
    "href": "field-methods/benthic_recruits.html#references",
    "title": "Coral Recruits",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_recruits.html#attachment-substrate",
    "href": "field-methods/benthic_recruits.html#attachment-substrate",
    "title": "Coral Recruits",
    "section": "Attachment Substrate",
    "text": "Attachment Substrate\nThe substrate to which coral recruits are attached is recorded using these categories:\n\n\n\nCCA (Crustose Coralline Algae) Pink to red calcified encrusting algae\n\n\n\nMacroalgae Base Attached to base of macroalgal holdfasts\n\n\n\nBare Substrate Directly attached to exposed rock or pavement\n\n\n\nCoral Rubble Attached to fragments of dead coral\n\n\n\nDead Coral (intact) Attached to intact dead coral structure\n\n\n\nOther Attached to other organisms or substrates",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Coral Recruits"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#references",
    "href": "field-methods/benthic_inverts.html#references",
    "title": "Invertebrates",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#special-taxonomic-considerations",
    "href": "field-methods/benthic_inverts.html#special-taxonomic-considerations",
    "title": "Invertebrates",
    "section": "Special Taxonomic Considerations",
    "text": "Special Taxonomic Considerations\n\nGiant Clams (Tridacnidae)\nDue to their ecological significance and vulnerability to harvesting, detailed data is collected for all giant clams:\n\nSpecies: Identify to species level (e.g., Tridacna maxima, T. squamosa)\nSize: Measure maximum shell length (cm) using calipers\nPosition: Record as (E) embedded in substrate, (L) loose on substrate, or (P) partially embedded\nCondition: Note any signs of bleaching, damage, or harvesting attempts\n\n\n\nCrown-of-Thorns Starfish (COTS)\nIn regions where Acanthaster spp. outbreaks are a concern, we collect additional data on each individual:\n\nSize: Measure diameter (cm) from arm tip to opposite arm tip\nActivity: Record as (F) feeding, (M) moving, or (R) resting\nPosition: Note substrate association (e.g., on live coral, dead coral, rubble)\nAggregation: Document density if multiple individuals present\nCondition: Note any visible injuries, disease signs, or predation marks\n\nThis enhanced data collection for COTS provides valuable information about population dynamics and potential outbreak conditions.\n\n\nCommercially Valuable Species\nFor species with particular economic importance within the survey region:\n\nSize structure: Collect measurements to assess population structure\nHabitat association: Document specific substrate or habitat preferences\nEvidence of harvesting: Note any signs of collection pressure\nJuvenile presence: Document abundance of juvenile stages if observed",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#integration-with-other-methods",
    "href": "field-methods/benthic_inverts.html#integration-with-other-methods",
    "title": "Invertebrates",
    "section": "Integration with Other Methods",
    "text": "Integration with Other Methods\nThe invertebrate survey data can be analyzed alongside other Pristine Seas survey methods:\n\nWith LPI data: Examining relationships between benthic composition and invertebrate communities\nWith fish data: Investigating predator-prey relationships and trophic cascades\nWith coral recruit data: Assessing potential impacts of invertebrate grazers on coral recruitment\nWith eDNA data: Comparing visual detection with molecular detection of invertebrate diversity",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  },
  {
    "objectID": "field-methods/benthic_inverts.html#limitations-and-considerations",
    "href": "field-methods/benthic_inverts.html#limitations-and-considerations",
    "title": "Invertebrates",
    "section": "Limitations and Considerations",
    "text": "Limitations and Considerations\nWhile the belt transect methodology is effective for surveying many mobile invertebrates, several limitations should be considered:\n\nHabitat complexity: Detection probability varies with substrate complexity\nCryptic behavior: Many invertebrates are hidden within complex reef structures\nNocturnal activity: Daytime surveys miss species active primarily at night\nDiver avoidance: Some mobile species actively avoid divers\nSpatial clumping: Patchy distribution may result in high variance between transects",
    "crumbs": [
      "Home",
      "Field Methods",
      "Underwater Visual Surveys (UVS)",
      "Benthos",
      "Invertebrates"
    ]
  }
]